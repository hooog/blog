<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Environment," />





  <link rel="alternate" href="/atom.xml" title="Hoooge's Blog" type="application/atom+xml" />






<meta name="description" content="本文参考- Machine learning with Scala by CDA 吴昊天 一、基础软件准备　　在进行分布式架构的学习前，首先需进行PC机的基础环境准备，由于Apache Hadoop是基于JAVA语言开发，所要求的系统环境适用于Windows、Linux和Mac OS操作系统。根据其适用程度，我们首推Linux系统或Mac OS系统，而二者相比选择Linux系统适用面更为广泛，因">
<meta name="keywords" content="Environment">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop分布式集群架构实验手册">
<meta property="og:url" content="http://www.ihoge.cn/2018/分布式集群架构实验手册.html">
<meta property="og:site_name" content="Hoooge&#39;s Blog">
<meta property="og:description" content="本文参考- Machine learning with Scala by CDA 吴昊天 一、基础软件准备　　在进行分布式架构的学习前，首先需进行PC机的基础环境准备，由于Apache Hadoop是基于JAVA语言开发，所要求的系统环境适用于Windows、Linux和Mac OS操作系统。根据其适用程度，我们首推Linux系统或Mac OS系统，而二者相比选择Linux系统适用面更为广泛，因">
<meta property="og:image" content="g:/屏幕截图/1.jpg">
<meta property="og:image" content="g:/屏幕截图/2.jpg">
<meta property="og:image" content="g:/屏幕截图/3.jpg">
<meta property="og:image" content="g:/屏幕截图/4.jpg">
<meta property="og:image" content="g:/屏幕截图/5.jpg">
<meta property="og:image" content="g:/屏幕截图/6.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/1.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/2.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/3.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/4.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/6.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/7.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/8.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/9.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/10.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/11.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/12.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/13.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/14.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/15.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/16.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/17.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/18.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/19.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/20.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/21.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/22.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/23.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/24.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/25.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/26.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/27.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/28.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/29.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/30.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/31.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/32.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/33.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/34.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/35.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/36.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/37.jpg">
<meta property="og:image" content="g:/屏幕截图/安装Ubuntu部分/38.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/1.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/2.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/3.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/4.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/5.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/6.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/7.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/8.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/9.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/10.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/11.jpg">
<meta property="og:image" content="file:///G:/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE/Ubuntu%E5%AE%89%E8%A3%85Hadoop%E9%83%A8%E5%88%86/12.jpg?lastModify=1514714541">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/13.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/15.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/16.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/17.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/18.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/19.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/20.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/21.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/22.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/23.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/25.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/26.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/27.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/29.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/30.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/31.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/32.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/33.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/34.jpg">
<meta property="og:image" content="g:/屏幕截图/Ubuntu安装Hadoop部分/35.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/1.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/2.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/14.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/15.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/3.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/4.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/11.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/12.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/13.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/19.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/16.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/19.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/20.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/21.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/1.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/2.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/3.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/4.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/5.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/6.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/7.jpg">
<meta property="og:image" content="g:/屏幕截图/分布式集群安装部分/8.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/5.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/6.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/7.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/9.jpg">
<meta property="og:image" content="g:/屏幕截图/其他组件安装部分/10.jpg">
<meta property="og:updated_time" content="2018-04-06T17:31:08.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop分布式集群架构实验手册">
<meta name="twitter:description" content="本文参考- Machine learning with Scala by CDA 吴昊天 一、基础软件准备　　在进行分布式架构的学习前，首先需进行PC机的基础环境准备，由于Apache Hadoop是基于JAVA语言开发，所要求的系统环境适用于Windows、Linux和Mac OS操作系统。根据其适用程度，我们首推Linux系统或Mac OS系统，而二者相比选择Linux系统适用面更为广泛，因">
<meta name="twitter:image" content="g:/屏幕截图/1.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.ihoge.cn/2018/分布式集群架构实验手册.html"/>





  <title>Hadoop分布式集群架构实验手册 | Hoooge's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/hooog" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hoooge's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Life is short</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Startseite
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            Über
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Kategorien
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archiv
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ihoge.cn/2018/分布式集群架构实验手册.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘知行">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hoooge's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Hadoop分布式集群架构实验手册</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Veröffentlicht am</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-03-15T11:59:21+08:00">
                2018-03-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">in</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>K
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <a id="more"></a>
<p>本文参考- Machine learning with Scala by CDA 吴昊天</p>
<h2 id="一、基础软件准备"><a href="#一、基础软件准备" class="headerlink" title="一、基础软件准备"></a>一、基础软件准备</h2><p>　　在进行分布式架构的学习前，首先需进行PC机的基础环境准备，由于Apache Hadoop是基于JAVA语言开发，所要求的系统环境适用于Windows、Linux和Mac OS操作系统。根据其适用程度，我们首推Linux系统或Mac OS系统，而二者相比选择Linux系统适用面更为广泛，因此本次教学我们将利用虚拟机运行Linux系统，并在其上进行分布式架构相关操作教学与实践。同时由于为了更加符合企业应用实际，我们推荐在后期学习过程中，使用模拟终端利用命令行操控虚拟机，并利用开源软件实现本机与虚拟机文件互传。</p>
<p>注：</p>
<ul>
<li>实验手册涉及软件安装均为开源或社区版免费软件；</li>
<li>软件下载及安装主要以Windows为例进行讲解，对于Mac OS也可类似进行安装与操作，如未特意说明，二者在下载、安装与使用过程中无明显区别；</li>
<li>该实验手册版本为2017年12月版，适用于CDA大数据分析师脱产班（第七期）课程分布式集群架构部分。</li>
</ul>
<h3 id="1-虚拟机软件选择与安装"><a href="#1-虚拟机软件选择与安装" class="headerlink" title="1.虚拟机软件选择与安装"></a>1.虚拟机软件选择与安装</h3><h4 id="1-1-主流虚拟机软件介绍与选择"><a href="#1-1-主流虚拟机软件介绍与选择" class="headerlink" title="1.1 主流虚拟机软件介绍与选择"></a>1.1 主流虚拟机软件介绍与选择</h4><p>　　就目前而言，VMware Workstation Pro是使用最为广泛、功能最为强大的虚拟机软件，主要用于IT开发和系统管理等商业环境，相比之下，其社区免费版VMware Workstation Player，虽然在近些年的更新中不断增加新的功能，但在功能上仍然有一定的局限。而开源虚拟软件Oracle VM VirtualBox，则在所有免费虚拟机软件中表现较为突出，成为大多数教学、实验等非商业环境中的首选，因此，本次教学将利用Oracle VM VirtualBox进行虚拟机安装。</p>
<h4 id="1-2-Virtual-Box下载与安装"><a href="#1-2-Virtual-Box下载与安装" class="headerlink" title="1.2 Virtual Box下载与安装"></a>1.2 Virtual Box下载与安装</h4><ul>
<li><p>Virtual Box下载</p>
<p>从<strong><a href="https://www.virtualbox.org/wiki/Downloads" target="_blank" rel="noopener">Virtual Box官方下载地址</a></strong>下载最新版本Virtual Box安装包（以5.2.4为例），官方下载地址同时提供Windows和Mac OS系统对应的版本。</p>
</li>
<li><p>Virtual Box安装</p>
</li>
</ul>
<p>打开已下载安装程序</p>
<p><img src="G:\屏幕截图\1.jpg" alt="1"></p>
<p>点击下一步</p>
<p><img src="G:\屏幕截图\2.jpg" alt="2"></p>
<p>选择安装位置，点击下一步</p>
<p><img src="G:\屏幕截图\3.jpg" alt="3"></p>
<p>根据自身安装需求进行选择，然后点击下一步</p>
<p><img src="G:\屏幕截图\4.jpg" alt="4"></p>
<p>点击是，进行后续操作</p>
<p><img src="G:\屏幕截图\5.jpg" alt="5"></p>
<p>点击安装，开始安装</p>
<p><img src="G:\屏幕截图\6.jpg" alt="6"></p>
<p>安装完成</p>
<h3 id="2-Linux操作系统选择与安装"><a href="#2-Linux操作系统选择与安装" class="headerlink" title="2.Linux操作系统选择与安装"></a>2.Linux操作系统选择与安装</h3><h4 id="2-1-Linux系统选择"><a href="#2-1-Linux系统选择" class="headerlink" title="2.1 Linux系统选择"></a>2.1 Linux系统选择</h4><p>　　Linux是类Unix操作系统，我们现在所谓的Linux操作系统，从严格意义上来说是指拥有Linux内核的操作系统，其中，Ubuntu和CentOS操作系统分别是桌面端和服务器端占比最高的开源操作系统，而这两个操作系统也将是本次讲学过程中主要涉及的两个操作系统。</p>
<ul>
<li><p>Ubuntu</p>
<p>拥有人性化的桌面操作界面，除商业用途外，也非常适合PC用户处理日常事务。该系统每隔6个月，也就是每年4月和10月发布一个新版本，一般以年月标注为版本号，如13.04、13.10等，其中，尾注为LTS（Long Term Support）的版本为长期支持版本，一般隔年的4月版本为长期支持版，如12.04 LTS、14.04LTS等，同时标注为Kylin的版本为中文支持版，由中文社区维护。</p>
</li>
<li><p>CentOS</p>
<p>Community Enterprise Operating System，中文译为社区企业操作系统，是RHEL（Red Hat Enterprise Linux）源码再编译的操作系统，由于其高稳定性，常用于企业级服务器。新版本CentOS大约每两年发布一次，并且每个新版本会定期（一般为6个月）更新一次。CentOS于2014年宣布加入Red Hat，但仍将保持免费。</p>
</li>
<li><p>Ubuntu与CentOS对比</p>
<p>对命令行操作系统不太熟悉的分布式集群架构初学者而言，Ubuntu友善的桌面操作系统将是更好的选择，而对于企业应用来说，更加稳定的CentOS系统无疑是更好的选择，同时抛弃了桌面操作系统的版本在系统资源占用方面也更有优势。本次课程在同时兼顾学习曲线和企业实际应用的情况下，主要将以Ubuntu操作系统为例进行教学，同时提供CentOS操作系统版本的分布式集群搭建的相关说明，以供学员课后自主学习。</p>
</li>
</ul>
<h4 id="2-2-Ubuntu操作系统选择与安装"><a href="#2-2-Ubuntu操作系统选择与安装" class="headerlink" title="2.2 Ubuntu操作系统选择与安装"></a>2.2 Ubuntu操作系统选择与安装</h4><h5 id="2-2-1系统选择"><a href="#2-2-1系统选择" class="headerlink" title="2.2.1系统选择"></a>2.2.1系统选择</h5><ul>
<li><p>系统版本选择</p>
<p>本次教学采用Ubuntu 14.04 LTS Kylin版本，值得注意的是，如果要安装Spark 2.1以上，则最好选择Ubuntu 16.04或更新版本系统。同时，对于内存大于4G的电脑，建议使用64位操作系统。</p>
</li>
<li><p>关于Kylin中文版</p>
<p>对于Ubuntu系统而言，由于有独立中文版本并且有中文社区进行维护，因此系统语言选择并不会对系统造成任何影响，但若采用别的系统，则需要在系统语言选择上多加考虑，如CentOS 7系统中选择中文可能会对HDP安装造成影响。</p>
</li>
</ul>
<h5 id="2-2-2系统安装"><a href="#2-2-2系统安装" class="headerlink" title="2.2.2系统安装"></a>2.2.2系统安装</h5><p>　　接下来，进行Ubuntu 14.04 LTS Kylin在Oracle VM VirtualBox中的安装。</p>
<ul>
<li><p>Ubuntu系统下载</p>
<p>在<strong><a href="http://www.ubuntukylin.com/" target="_blank" rel="noopener">Ubuntu中文社区（优麒麟）官网</a></strong>或<strong><a href="https://www.ubuntu.com/download" target="_blank" rel="noopener">Ubuntu官网下载地址</a></strong>选择对应系统版本进行下载，本教程采用Ubuntu 14.04 LTS Kylin 64位系统版本。</p>
</li>
<li><p>Ubuntu系统安装</p>
<ul>
<li><p>开启虚拟化</p>
<p>由于64操作系统的虚拟机必须要求主机CPU开启虚拟化，因此我们在正式安装虚拟机前需检查电脑是否已经开启虚拟化，如果虚拟化未开启，则在VirtualBox中就将无法选择64位操作系统进行虚拟机安装。对于大多数PC机而言，开启虚拟化需要进入BIOS进行设置，不同厂商电脑进入BIOS界面方法不同，此部分请同学们自行根据自身电脑品牌，进入BIOS界面进行设置，此处以HP台式机为例进行说明。</p>
</li>
<li><p>利用VirtualBox搭建虚拟机环境</p>
<p>打开VirtualBox点击新建虚拟机</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\1.jpg" alt="1"></p>
<p>输入虚拟机名称，此处可将系统名称作为虚拟机电脑名称，同时在类型中选择Linux系统，并且选择Ubuntu64位版本，点击下一步</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\2.jpg" alt="2"></p>
<p>对于操作系统内存选择，4G内存电脑建议分配1G内存给虚拟机，8G内存电脑则可分配2G给虚拟机，16G及以上则建议分配3G及以上给虚拟机，此处以3G为例进行安装，调整完毕后选择下一步</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\3.jpg" alt="3"></p>
<p>接下来，选择现在创建虚拟硬盘（c），点击创建</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\4.jpg" alt="4"></p>
<p>接下来，选择VDI（VirtualBox磁盘映像），点击下一步</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\6.jpg" alt="6"></p>
<p>虚拟硬盘选择动态分配，点击下一步</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\7.jpg" alt="7"></p>
<p>接下来选择虚拟机备份地址，建议放置于磁盘空间较大的分区，同时分配虚拟机可使用的最大硬盘空间，如果仅作为学习使用，则20G足以，如果需要安装HDP，则至少需要40G以上，此处以20G为例进行安装。选择完毕后选择创建，</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\8.jpg" alt="8"></p>
</li>
<li><p>安装Ubuntu系统</p>
<p>点击设置</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\9.jpg" alt="9"></p>
<p>在设置中选择存储，并点击没有盘片，在属性栏中点击盘片图标</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\10.jpg" alt="10"></p>
<p>在弹出的窗口中选择虚拟光盘文件，即下载好的操作系统镜像文件位置，然后点击打开</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\11.jpg" alt="11"></p>
<p>完成后自动返回存储界面，将显示已经有光盘镜像文件，点击OK</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\12.jpg" alt="12"></p>
<p>在返回的Virtual界面中选择刚才配置好的虚拟机，点击启动</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\13.jpg" alt="13"></p>
<p>进入Ubuntu系统安装界面，Ubuntu系统会自动捕捉鼠标，操作起来相对人性化</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\14.jpg" alt="14"></p>
<p>选择中文（简体），单机安装Ubuntu Kylin</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\15.jpg" alt="15"></p>
<p>更新或安装第三方软件，可根据自身喜好选择，无论选择与否对安装Hadoop集群不会造成太大影响，此处以不选择为例进行安装，点击继续</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\16.jpg" alt="16"></p>
<p>安装类型选择其他选项，自行创建、调整分区，点击继续</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\17.jpg" alt="17"></p>
<p>点击新建分区表</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\18.jpg" alt="18"></p>
<p>在弹出的对话框中选择继续</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\19.jpg" alt="19"></p>
<p>创建分区，添加交换空间和根目录，首先选择空闲，然后点击左下方加号</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\20.jpg" alt="20"></p>
<p>在弹出的对话框中，选择1024M（1G）作为交换空间，新建分区类型为主分区，新建分区位置为空间起始位置，用于选择交换空间，点击确定</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\21.jpg" alt="21"></p>
<p>继续创建根目录，在返回的界面中，点击空闲，再点击左下方加号</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\22.jpg" alt="22"></p>
<p>在弹出对话框中，只更改挂载点为/，其他选项不变，点击确定</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\23.jpg" alt="23"></p>
<p>然后开始安装，在返回的界面中点击现在安装</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\24.jpg" alt="24"></p>
<p> 选择时区，保持默认东八区既可，点击继续<img src="G:\屏幕截图\安装Ubuntu部分\25.jpg" alt="25"></p>
<p>键盘布局保持默认既可，即左右两边都选汉语，点击继续</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\26.jpg" alt="26"></p>
<p>设置用户名、计算机名和登录密码，根据可自身喜好进行填写，由于在后续搭建集群时将反复输入账户密码，建议设置短密码。设置完毕后点击继续</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\27.jpg" alt="27"></p>
<p>接下来，系统将开始自动安装，请保持网络通畅，并耐心等待</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\28.jpg" alt="28"></p>
<p>安装完成后，点击现在重启，以完成安装</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\29.jpg" alt="29"></p>
<p>重启时，可能会卡在如下界面</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\30.jpg" alt="30"></p>
<p>此时可以自行关闭虚拟机再打开，点击关闭按钮，在弹出对话框中选择强制退出</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\31.jpg" alt="31"></p>
<p>再次点击启动按钮，输入账户密码，进入操作系统</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\32.jpg" alt="32"></p>
<p>对于弹出的升级操作系统提示，选择不升级</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\33.jpg" alt="33"></p>
<p>接下来，安装Ubuntu系统增强功能，以方便后续操作。点击设备，在弹出对话框中选择安装增强功能</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\34.jpg" alt="34"></p>
<p>在弹出的提示框中，选择运行（我们能看到，在未安装增强功能前，窗口化的虚拟机操作系统缩放不是很方便）</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\35.jpg" alt="35"></p>
<p>输入密码，进行授权</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\36.jpg" alt="36"></p>
<p>安装完成后，单机回车退出命令行界面</p>
<p><img src="G:\屏幕截图\安装Ubuntu部分\37.jpg" alt="37"></p>
<p>接下来，重启虚拟机操作系统，既可体验安装完增强版后的Ubuntu系统了，可以看到，系统支持自动缩放了。</p>
<p>点击桌面左侧火狐浏览器按钮，检测是否能够正常上网<img src="G:\屏幕截图\安装Ubuntu部分\38.jpg" alt="38"></p>
<p>至此，Ubuntu安装过程正式完成。</p>
</li>
</ul>
</li>
</ul>
<h3 id="3-其他功能软件准备与安装"><a href="#3-其他功能软件准备与安装" class="headerlink" title="3.其他功能软件准备与安装"></a>3.其他功能软件准备与安装</h3><h4 id="3-1-模拟终端软件下载与安装"><a href="#3-1-模拟终端软件下载与安装" class="headerlink" title="3.1 模拟终端软件下载与安装"></a>3.1 模拟终端软件下载与安装</h4><p>　　主要将用于远程连接主机，在操作集群或者连接服务器时将大幅简化许多操作。</p>
<ul>
<li><p>基于Windows操作系统</p>
<p>推荐使用XShell</p>
<p>从<strong><a href="http://www.netsarang.com/download/down_form.html?code=522" target="_blank" rel="noopener">Xshell官方下载地址</a></strong>下载Xshell 5（需选择家庭或学生用户）</p>
<p>利用Xshell连接虚拟机，以及后续安装的分布式集群。</p>
</li>
</ul>
<h4 id="3-2-图形化SFTP（安全文件传输协议）客户端下载"><a href="#3-2-图形化SFTP（安全文件传输协议）客户端下载" class="headerlink" title="3.2 图形化SFTP（安全文件传输协议）客户端下载"></a>3.2 图形化SFTP（安全文件传输协议）客户端下载</h4><p>　　该软件主要用于主机与虚拟机之间文件互传，若采用VMware安装虚拟机，则无需额外软件提供文件互传功能，但若使用VirtualBox或在远程连接服务器时，利用SFTP客户端进行文件传输就显得非常重要。</p>
<ul>
<li><p>基于Windows操作系统</p>
<p>推荐使用WinSCP进行安装，在<strong><a href="https://winscp.net/eng/download.php" target="_blank" rel="noopener">官网下载地址</a></strong>选择最新版进行下载安装，与一般软件安装过程相同，此处不做赘述。</p>
</li>
</ul>
<h2 id="二、Hadoop单机模式与伪分布式的安装与配置"><a href="#二、Hadoop单机模式与伪分布式的安装与配置" class="headerlink" title="二、Hadoop单机模式与伪分布式的安装与配置"></a>二、Hadoop单机模式与伪分布式的安装与配置</h2><h3 id="1-Hadoop版本选择"><a href="#1-Hadoop版本选择" class="headerlink" title="1.Hadoop版本选择"></a>1.Hadoop版本选择</h3><p>　　Hadoop版本主要分为原生Apache Hadoop版和Hadoop商业发行版两种，而其中商业发行版Hadoop多为原生Apache Hadoop的集群模式下的优化版，除少数社区版外，商业发行版大多需要付费使用，且对于初学者而言使用难度较大，因此本教程主要采用Apache Hadoop进行安装与使用方面教学，同时在教程的最后，我们将简单介绍HortonWorks公司的Hadoop发行版HDP（Hortonworks Data Platform）安装使用方法。</p>
<p>　　而对于Apache Hadoop的版本选择，在兼顾实用性及学员机器性能的情况下，考虑安装Hadoop 2.2.0版本。</p>
<h3 id="2-Hadoop下载与安装"><a href="#2-Hadoop下载与安装" class="headerlink" title="2.Hadoop下载与安装"></a>2.Hadoop下载与安装</h3><h4 id="2-1-Apache-Hadoop下载"><a href="#2-1-Apache-Hadoop下载" class="headerlink" title="2.1 Apache Hadoop下载"></a>2.1 Apache Hadoop下载</h4><p>　　在<strong><a href="http://hadoop.apache.org/" target="_blank" rel="noopener">Apache Hadoop官网</a></strong>可下载Hadoop生态部分核心组件，同时也可查阅Hadoop各版本说明及操作指南，以及各版本Hadoop源码，在下载时注意选择镜像站点，推荐在清华站点或者阿里云站点进行下载，在后续的其他核心组件下载安装时也是如此。选择Hadoop 2.2.0进行下载。</p>
<h4 id="2-2-Apache-Hadoop安装"><a href="#2-2-Apache-Hadoop安装" class="headerlink" title="2.2 Apache Hadoop安装"></a>2.2 Apache Hadoop安装</h4><h5 id="2-2-1-Ubuntu中安装Hadoop"><a href="#2-2-1-Ubuntu中安装Hadoop" class="headerlink" title="2.2.1 Ubuntu中安装Hadoop"></a>2.2.1 Ubuntu中安装Hadoop</h5><ul>
<li><p>打开安装好的Ubuntu虚拟机，打开命令行界面（control+alt+t）</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\1.jpg" alt="1"></p>
</li>
<li><p>创建Hadoop用户</p>
<p>首先需创建Hadoop用户，在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo useradd -m hadoop -s /bin/bash</span><br></pre></td></tr></table></figure>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo命令</span><br><span class="line">教程中会大量使用到sudo命令。sudo是ubuntu中一种权限管理机制，管理员可以授权给一些普通用户去执行一些需要root权限执行的操作。当使用sudo命令时，就需要输入您当前用户的密码。</span><br></pre></td></tr></table></figure>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">粘贴</span><br><span class="line">Ubuntu操作系统中粘贴快捷键为control+shift+v，复制为control+shift+c，注意要在设置中开启粘贴功能。</span><br></pre></td></tr></table></figure>
<p>为Hadoop用户创建密码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo passwd hadoop</span><br></pre></td></tr></table></figure>
<p>按提示输入两次密码</p>
<p>为Hadoop用户添加管理员权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo adduser hadoop sudo</span><br></pre></td></tr></table></figure>
<p>然后选择注销，重新选择Hadoop用户进行登录，也可直接切换用户</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\2.jpg" alt="2"></p>
</li>
<li><p>更新apt</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>
<p>若在更新过程中出现校验和不符的情况，则需要更新软件源，更新软件源在设置-软件和更新中进行设置，在“下载自”中选择阿里云镜像站点后再次尝试</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\3.jpg" alt="3"></p>
</li>
<li><p>安装vim</p>
<p>vim作为vi文本编辑器的增强版，在后续很多情景下都将发挥较大作用，因此建议提前安装，如果没安装vim，也可采用gedit或者vi文本编辑器进行文本编辑</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install vim</span><br></pre></td></tr></table></figure>
<p>若需要确认，输入y即可</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vim简单操作指南</span><br><span class="line">vim的常用模式有分为命令模式，插入模式，可视模式，正常模式。本教程中，只需要用到正常模式和插入模式。二者间的切换即可以帮助你完成本指南的学习。</span><br><span class="line">正常模式</span><br><span class="line">正常模式主要用来浏览文本内容。一开始打开vim都是正常模式。在任何模式下按下Esc键就可以返回正常模式</span><br><span class="line">插入编辑模式</span><br><span class="line">插入编辑模式则用来向文本中添加内容的。在正常模式下，输入i键即可进入插入编辑模式</span><br><span class="line">退出vim</span><br><span class="line">如果有利用vim修改任何的文本，一定要记得保存。Esc键退回到正常模式中，然后输入:wq即可保存文本并退出vim</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装SSH</p>
<p>SSH是一种网络协议，用于计算机之间加密登录，在配置集群过程中必不可少。Ubuntu 默认已安装了 SSH client，此外还需要安装 SSH server</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openssh-server</span><br></pre></td></tr></table></figure>
<p>尝试使用ssh登录本机</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh localhost</span><br></pre></td></tr></table></figure>
<p>首次登陆时会有如下提示，先输入密码，然后输入账户密码既可</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\4.jpg" alt="4"></p>
<p>登录成功字样</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\5.jpg" alt="5"></p>
<p>在命令行中输入exit既可退出</p>
</li>
<li><p>配置SSH无密码登录</p>
<p>目前登录仍然需要密码，在集群配置过程中将非常麻烦，因此需要配置免密码登录</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh/                             # 若没有该目录，请先执行一次ssh localhost</span><br><span class="line">ssh-keygen -t rsa                      # 会有提示，都按回车就可以</span><br><span class="line">cat ./id_rsa.pub &gt;&gt; ./authorized_keys  # 加入授权</span><br></pre></td></tr></table></figure>
<p>再次使用ssh local命令，此时无需密码既可登录。在进行后续操作前，记得exit退出</p>
</li>
<li><p>安装JAVA</p>
<p>对于运行Hadoop集群而言， Oracle 的 JDK或是 OpenJDK均可，部分新版Hadoop生态组件需要JAVA8支持，此处由于安装Hadoop 2.2.0版本，安装JAVA7既可。</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install openjdk-7-jre openjdk-7-jdk</span><br></pre></td></tr></table></figure>
<p>安装完成后，输入下述命令找到JDK安装路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dpkg -L openjdk-7-jdk | grep '/bin/javac'</span><br></pre></td></tr></table></figure>
<p>根据提示找到路径，如若出现如下提示</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\6.jpg" alt="6"></p>
<p>则说明java安装路径为/usr/lib/jvm/java-7-openjdk-i386</p>
<p>配置JAVA环境，本文中在profile中进行环境变量的配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>在弹出框中输入i，进入编辑模式，并在起始行输入JAVA路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386</span><br></pre></td></tr></table></figure>
<p>输入完成后，esc退出编辑模式，并输入:wq保存退出</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.profile</span><br></pre></td></tr></table></figure>
<p>使刚才配置的环境变量生效</p>
</li>
<li><p>验证JAVA环境配置成功</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo $JAVA_HOME                # 检验变量值，打印设置的环境变量路径</span><br><span class="line">java -version</span><br><span class="line"><span class="meta">$</span><span class="bash">JAVA_HOME/bin/java -version   <span class="comment"># 与直接执行 java -version 一样</span></span></span><br></pre></td></tr></table></figure>
<p>若出现下述字样，则说明JAVA环境变量配置成功</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\7.jpg" alt="7"></p>
</li>
</ul>
<ul>
<li><p>安装Hadoop 2.2.0</p>
<p>一般来说，虚拟机/服务中安装文件主要有两种方式，一种是主机或节点间互传，第二种则是在直接在虚拟机/服务器中连接下载点进行下载，由于本次Hadoop安装版本为2.2.0，属于中国区镜像站点已经不再维护版本，而从其他站点下载速度较慢，因此考虑从主机用SFTP软件直接传输安装文件至虚拟机。</p>
<ul>
<li><p>更改虚拟机网络设置</p>
<p>VirtualBox默认虚拟机网络配置为NAT网络，此时虚拟机与主机共享网络，无论是Xshell和Winscp均无法正确获得虚拟机IP地址，因此首先要更改虚拟机网络配置。为了兼顾企业级实用性，此处考虑采用NAT模式和host-only（仅主机）双网卡模式进行配置</p>
<p>关闭虚拟机，在控制台中选择设置，进入设置界面</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\8.jpg" alt="8"></p>
<p>在网络中，网卡1保留NAT网络设置</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\9.jpg" alt="9"></p>
<p>选中网卡2，勾选启用网络连接，同时选择连接方式为仅主机适配器</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\10.jpg" alt="10"></p>
<p>点击OK，完成配置，并启动虚拟机</p>
</li>
<li><p>查询虚拟机IP</p>
<p>打开命令行，输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\11.jpg" alt="11"></p>
<p>在eth1中，本机inet网址为192.168.56.101，就以此ip采用WinSCP进行连接</p>
</li>
<li><p>利用WinSCP进行连接</p>
<p>打开WinSCP，点击新建连接，输入IP、登录账户（hadoop），及登录密码</p>
<p><img src="file:///G:/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE/Ubuntu%E5%AE%89%E8%A3%85Hadoop%E9%83%A8%E5%88%86/12.jpg?lastModify=1514714541" alt="img"></p>
<p>点击登录，在弹出的提示框中点击是</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\13.jpg" alt="13"></p>
<p>进入界面，通过拖拉拽既可实现文件传输</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\15.jpg" alt="15"></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>利用Xshell连接虚拟机</p>
<p>  在后续的分布式集群安装部署过程中，将同时打开多个虚拟机，此时来回切换窗口进行命令行输行不是很方便，同时对于操作服务器时，也不太可能直接利用服务器提供的服务台进行命令行输入，基本也是采用Xshell或其他模拟终端软件进行服务器操作，因此我们需要提前熟悉利用模拟终端软件进行虚拟机控制。</p>
<p>  打开Xshell，点击新建</p>
</li>
</ul>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\16.jpg" alt="16"></p>
<p>​         在弹出的对话框中，输入IP、名称</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\17.jpg" alt="17"></p>
<p>​         选择用户身份验证，输入账户密码</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\18.jpg" alt="18"></p>
<p>其余可根据自身选好进行配置，如窗口、外观等，配置完成后点击确定，进行连接，在弹出的对话框中选择保存并接受</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\19.jpg" alt="19"></p>
<p>出现下述对话框则说明连接成功</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\20.jpg" alt="20"></p>
<p>接下大部分命令行操作均会在Xshell中进行</p>
<ul>
<li><p>利用WinSCP将安装文件Hadoop 2.2.0传输至下载文件夹中</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\21.jpg" alt="21"></p>
</li>
<li><p>在Xshell中输入命令，安装Hadoop</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                                 # 进入“下载”文件夹</span><br><span class="line">sudo tar -zxf hadoop-2.2.0.tar.gz -C /usr/local          # 解压到/usr/local中</span><br><span class="line">cd /usr/local/</span><br><span class="line">sudo mv ./hadoop-2.2.0/ ./hadoop                         # 将文件夹名改为hadoop</span><br><span class="line">sudo chown -R hadoop ./hadoop                            # 修改文件权限</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\22.jpg" alt="22"></p>
</li>
<li><p>配置Hadoop环境变量</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>在弹出的框体中输入i进入编辑模式，然后输入下述内容</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\23.jpg" alt="23"></p>
<p>按esc退出编辑模式，输入:wq保存并退出</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.profile</span><br></pre></td></tr></table></figure>
<p>使之生效。</p>
<p><strong>注：在后续环境变量设置中，将不再反复赘述编辑器打开关闭过程，只对需要更改的环境变量内容进行说明。</strong></p>
</li>
<li><p>检验Hadoop是否安装成功</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\25.jpg" alt="25"></p>
<p>出现版本号则说明安装配置成功</p>
</li>
<li><p>进一步配置Hadoop环境变量</p>
<p>通常而言，Hadoop安装到此为止就已经结束，但为了避免后续可能出现的bug以及便于使用，此处增加一些Hadoop环境变量，改变后profile中环境变量相关内容汇总如下:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">JAVA</span></span><br><span class="line">export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"><span class="meta">#</span><span class="bash">Hadoop</span></span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export YARN_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export HADOOP_OPTS="-DJava.library.path=$HADOOP_HOME/lib"</span><br><span class="line">export JAVA_LIBRARY_PATH=$HADOOP_HOME/lib/native:$JAVA_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\26.jpg" alt="26"></p>
</li>
</ul>
<h3 id="3-Hadoop单机模式配置与运行"><a href="#3-Hadoop单机模式配置与运行" class="headerlink" title="3.Hadoop单机模式配置与运行"></a>3.Hadoop单机模式配置与运行</h3><p>　　Hadoop 默认模式为非分布式模式（本地模式），无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行调试。此处运行部分Hadoop自带MapReduce例子来验证Hadoop能够正常运行，同时体验Hadoop中MapReduce运行命令格式。</p>
<p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop            # 进入Hadoop安装文件夹</span><br><span class="line">mkdir ./input                   # 创建输入文件夹</span><br><span class="line">cp ./etc/hadoop/*.xml ./input   # 将配置文件作为输入文件</span><br><span class="line">./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep ./input ./output 'dfs[a-z.]+'           # 运行MapReduce中grep例子，筛选符合正则表达式dfs[a-z]+的单词并统计其出现的次数，并将结果放入output文件夹中</span><br><span class="line">cat ./output/*                  # 查看运行结果</span><br></pre></td></tr></table></figure>
<p>出现下述结果则说明运行成功</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\27.jpg" alt="27"></p>
<p>注：若要重复运行程序，需更改输出文件夹位置，或清空原输出文件夹</p>
<p>删除原文件夹使用命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -r ./output</span><br></pre></td></tr></table></figure>
<h3 id="4-Hadoop伪分布式配置与运行"><a href="#4-Hadoop伪分布式配置与运行" class="headerlink" title="4.Hadoop伪分布式配置与运行"></a>4.Hadoop伪分布式配置与运行</h3><p>　　Hadoop 可以在单节点上以伪分布式的方式运行，此时Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。Hadoop通过改变其配置文件来更改运行模式，进行伪分布式运行时需要更改core-site.xml、hdfs-site.xml、mapred-site.xml和yarn-site.xml四个配置文件。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。</p>
<h4 id="4-1-修改hadoop-env-sh"><a href="#4-1-修改hadoop-env-sh" class="headerlink" title="4.1 修改hadoop-env.sh"></a>4.1 修改hadoop-env.sh</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop/etc/hadoop                  <span class="comment"># 进入hadoop配置文件夹</span></span><br><span class="line">vim hadoop-env.sh</span><br></pre></td></tr></table></figure>
<p>在弹出的框体中输入</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386</span><br></pre></td></tr></table></figure>
<h4 id="4-2-修改core-site-xml文件"><a href="#4-2-修改core-site-xml文件" class="headerlink" title="4.2 修改core-site.xml文件"></a>4.2 修改<strong>core-site.xml</strong>文件</h4><p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>
<p>在弹出的框体中输入配置内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="4-3-修改hdfs-site-xml文件"><a href="#4-3-修改hdfs-site-xml文件" class="headerlink" title="4.3 修改hdfs-site.xml文件"></a>4.3 修改<strong>hdfs-site.xml</strong>文件</h4><p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>
<p>在弹出的框体中输入配置内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="4-4-修改mapred-site-xml文件"><a href="#4-4-修改mapred-site-xml文件" class="headerlink" title="4.4 修改mapred-site.xml文件"></a>4.4 修改mapred-site.xml文件</h4><p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml  # 复制模板</span><br><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure>
<p>在弹出的框体中输入配置内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="4-5-修改yarn-site-xml文件"><a href="#4-5-修改yarn-site-xml文件" class="headerlink" title="4.5 修改yarn-site.xml文件"></a>4.5 修改yarn-site.xml文件</h4><p>在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>在弹出的框体中输入配置内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce_shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="4-6启动集群"><a href="#4-6启动集群" class="headerlink" title="4.6启动集群"></a>4.6启动集群</h4><p>在运行伪分布式前，需先对NameNode进行格式化，在命令行中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>
<p>若出现successfully formatted字样，则说明格式化成功</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\29.jpg" alt="29"></p>
<p>启动hadoop集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh                   # 一次性启动所有服务</span><br></pre></td></tr></table></figure>
<p>或使用以下命令单独启动各项服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>利用jps命令查看是否启动成功，如果出现下述进程，则证明启动成功</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\30.jpg" alt="30"></p>
<p>启动后，利用Web端口检测集群运行情况</p>
<ul>
<li><p>ResourceManager Web界面</p>
<ul>
<li>虚拟机中浏览器中输入：<a href="http://localhost:8088" target="_blank" rel="noopener">http://localhost:8088</a></li>
</ul>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\31.jpg" alt="31"></p>
</li>
<li><p>NameNode HDFS Web界面</p>
<ul>
<li>虚拟机中浏览器中输入：<a href="http://localhost:50070" target="_blank" rel="noopener">http://localhost:50070</a></li>
</ul>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\32.jpg" alt="32"></p>
</li>
</ul>
<h4 id="4-7-测试运行"><a href="#4-7-测试运行" class="headerlink" title="4.7 测试运行"></a>4.7 测试运行</h4><p>接下来，测试grep例子在伪分布式集群模式上的运行</p>
<ul>
<li><p>在HDFS中放置输入文件</p>
<p>由于伪分布式运行时，数据从HDFS上进行读取，在上传数据至HDFS之前，我们需要在HDFS中创建用户目录。关于HDFS相关操作指令，详见附录一：HDFS基本操作指令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir -p /user/hadoop</span><br></pre></td></tr></table></figure>
<p>接着，我们选取hadoop配置文件夹中的xml文件作为输入文件复制到HDFS系统中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -mkdir input</span><br><span class="line">cd /usr/local/hadoop</span><br><span class="line">hdfs dfs -put ./etc/hadoop/*.xml input</span><br></pre></td></tr></table></figure>
<p>查看HDFS中文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -ls input</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行grep例子</p>
<p>伪分布式运行 MapReduce 作业的方式跟单机模式相同，只是读取文件和输出文件保存均在HDFS中</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-*.jar grep input output 'dfs[a-z.]+'</span><br></pre></td></tr></table></figure>
<p>运行过程部分如下所示：</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\33.jpg" alt="33"></p>
<p>查看保存在HDFS中的运行结果</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -cat output/*</span><br></pre></td></tr></table></figure>
<p>运行结果如下所示</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\34.jpg" alt="34"></p>
<p>当然，我们也可以将结果取回本地</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop</span><br><span class="line">rm -r ./output                          # 先删除本地的 output 文件夹（如果存在）</span><br><span class="line">hdfs dfs -get output ./output           # 将 HDFS 上的 output 文件夹拷贝到本机</span><br><span class="line">cat ./output/*</span><br></pre></td></tr></table></figure>
<p>注意，Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfs -rm -r output    # 删除 output 文件夹</span><br></pre></td></tr></table></figure>
<p>运行完成后，在8088端口中能看到完成的任务概况</p>
<p><img src="G:\屏幕截图\Ubuntu安装Hadoop部分\35.jpg" alt="35"></p>
</li>
</ul>
<h2 id="三、Hadoop生态部分核心组件安装与配置"><a href="#三、Hadoop生态部分核心组件安装与配置" class="headerlink" title="三、Hadoop生态部分核心组件安装与配置"></a>三、Hadoop生态部分核心组件安装与配置</h2><p>　　在安装完成伪分布式后，我们还要进一步在现有的虚拟机中安装其他Hadoop生态中的核心组件，以进一步完善集群功能。Hadoop生态中各常用组件及其主要功能一览如下：</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Objective</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Data Access</td>
<td>Pig</td>
<td>一种数据流语言和运行环境，适合于使用Hadoop和MapReduce平台来查询大型半结构化数据集。</td>
</tr>
<tr>
<td></td>
<td>Hive</td>
<td>一个基于Hadoop的数据仓库工具，可以用于对Hadoop文件中的数据集进行数据整理、特殊查询和分析存储。</td>
</tr>
<tr>
<td></td>
<td>HCatalog</td>
<td>基于Hive的对Hadoop中表和底层数据管理统一管理和服务平台。</td>
</tr>
<tr>
<td></td>
<td>Tez</td>
<td>Tez是Apache开源的支持DAG作业的计算框架，直接源于MapReduce框架，Hortonworks把Tez应用到数据仓库Hive的优化中，使得性能提升了约100倍。</td>
</tr>
<tr>
<td></td>
<td>Storm</td>
<td>是一个免费、开源的分布式实时计算系统，其对于实时计算的意义类似于Hadoop对于批处理的意义。</td>
</tr>
<tr>
<td></td>
<td>HBase</td>
<td>是一个提供高可靠性、高性能、可伸缩、实时读写、分布式的列式数据库，一般采用HDFS作为其底层数据存储。</td>
</tr>
<tr>
<td></td>
<td>Spark</td>
<td>是一个高性能的、集诸多计算功能于一身的分布式计算框架。</td>
</tr>
<tr>
<td></td>
<td>Solr</td>
<td>Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。</td>
</tr>
<tr>
<td>Data Management</td>
<td>HDFS</td>
<td>Hadoop分布式文件系统，是Hadoop两大核心项目之一。</td>
</tr>
<tr>
<td></td>
<td>YARN</td>
<td>新一代资源调度框架。</td>
</tr>
<tr>
<td>Data Governance and Workflow</td>
<td>Falcon</td>
<td>是一个面向Hadoop的、新的数据处理和管理平台,设计用于数据移动、数据管道协调、生命周期管理和数据发现。</td>
</tr>
<tr>
<td></td>
<td>Atlas</td>
<td>是一个可伸缩和可扩展的核心功能治理服务，企业可以利用它高效的管理 Hadoop 以及整个企业数据生态的集成。</td>
</tr>
<tr>
<td></td>
<td>Sqoop</td>
<td>用于改进数据的互操作性，主要用来在Hadoop和关系型数据库之间交换数据。</td>
</tr>
<tr>
<td></td>
<td>Flume</td>
<td>是cloudera提供的一个高可用的、高可靠的、分布式的海量日志采集、聚合和传输的系统。</td>
</tr>
<tr>
<td></td>
<td>Kafka</td>
<td>是LinkIn公司开发的一种高吞吐量的分布式发布订阅消息系统，在大数据生态中可作为数据交换枢纽，不同类型的分布式系统可统一接入Kafka。</td>
</tr>
<tr>
<td>Operations</td>
<td>Cloudbreak</td>
<td>用于在云端部署Hadoop集群。</td>
</tr>
<tr>
<td></td>
<td>Ambari</td>
<td>是一种基于Web的工具，支持Apache Hadoop集群的安装、部署、配置和管理。</td>
</tr>
<tr>
<td></td>
<td>ZooKeeper</td>
<td>是高效可靠的协同工作系统，提供分布式锁之类的服务，用于构建分布式应用，减轻分布式应用程序锁承担的协调任务。</td>
</tr>
<tr>
<td></td>
<td>Ooize</td>
<td>是一种框架,它让我们可以把多个Map/Reduce作业组合到一个逻辑工作单元中。</td>
</tr>
<tr>
<td>Security</td>
<td>Ranger</td>
<td>提供一个集中式安全管理框架, 并解决授权和审计，它可以对Hadoop生态的组件如HDFS、Yarn、Hive、Hbase等进行细粒度的数据访问控制。</td>
</tr>
<tr>
<td></td>
<td>Knox</td>
<td>是为了简化和标准化发布和实现安全的 Hadoop 集群,通过集中式的 REST APIs 访问服务。</td>
</tr>
<tr>
<td>NoteBook</td>
<td>Zeppelin</td>
<td>基于Hadoop集群的科学计算平台，提供类Jupyter功能，但远比Jupyter更深层次嵌入Hadoop生态，现已成为Apache顶级项目</td>
</tr>
</tbody>
</table>
<p> 本课程中，根据组件功能，我们选取以下组件进行安装：</p>
<table>
<thead>
<tr>
<th>Category</th>
<th>Objective</th>
<th>releases</th>
</tr>
</thead>
<tbody>
<tr>
<td>Operations</td>
<td>ZooKeeper</td>
<td></td>
</tr>
<tr>
<td>Data Governance and Workflow</td>
<td>Sqoop</td>
<td></td>
</tr>
<tr>
<td>Data Access</td>
<td>Hive</td>
<td></td>
</tr>
<tr>
<td></td>
<td>HBase</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Spark</td>
<td></td>
</tr>
<tr>
<td>NoteBook</td>
<td>Zeppelin</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>同时，本部所有组件暂时以单机模式或伪分布式进行安装，在后续部署分布式集群时，再对各组件进行配置修改，以符合集群模式运行要求。</p>
<h3 id="1-ZooKeeper安装与配置"><a href="#1-ZooKeeper安装与配置" class="headerlink" title="1.ZooKeeper安装与配置"></a>1.ZooKeeper安装与配置</h3><p>####1.1 ZooKeeper下载</p>
<p>　　在<strong><a href="http://zookeeper.apache.org/" target="_blank" rel="noopener">ZooKeeper官网</a></strong>可下载最新版本ZooKeeper，并且能够查阅版本改动说明，本次课程采用3.4.6版本进行安装。可以采用WinSCP传输zookeeper-3.4.6.tar至虚拟机“下载”文件夹中，再进行后续安装。</p>
<h4 id="1-2-ZooKeeper安装与配置"><a href="#1-2-ZooKeeper安装与配置" class="headerlink" title="1.2 ZooKeeper安装与配置"></a>1.2 ZooKeeper安装与配置</h4><ul>
<li><p>ZooKeeper解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                              # 进入下载文件夹</span><br><span class="line">sudo tar -zxf zookeeper-3.4.6.tar.gz -C /usr/local    # 安装至/usr/local文件夹内</span><br><span class="line">cd /usr/local                                         # 进入/usr/local文件夹</span><br><span class="line">sudo mv ./zookeeper-3.4.6/ ./zookeeper                # 更名为zookeeper</span><br><span class="line">sudo chown -R hadoop ./zookeeper                      # 修改zookeeper权限</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改ZooKeeper配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zookeeper/conf                          # 进入ZooKeeper配置文件目录</span><br><span class="line">sudo cp zoo_sample.cfg zoo.cfg                        # 复制配置样例文件为正式配置文件</span><br><span class="line">vim zoo.cfg                                           # 进入配置文件</span><br></pre></td></tr></table></figure>
<p>关键参数解读：</p>
<ul>
<li>tickTime<br>时长单位为毫秒，为zk使用的基本时间度量单位。例如，1 <em> tickTime是客户端与zk服务端的心跳时间，2 </em> tickTime是客户端会话的超时时间。<br>tickTime的默认值为2000毫秒，更低的tickTime值可以更快地发现超时问题，但也会导致更高的网络流量（心跳消息）和更高的CPU使用率（会话的跟踪处理）。</li>
<li>clientPort<br>zk服务进程监听的TCP端口，默认情况下，服务端会监听2181端口。</li>
<li>dataDir<br>用于配置存储快照文件的目录。如果没有配置dataLogDir，那么事务日志也会存储在此目录。默认配置为临时文件。</li>
</ul>
<p>在运行单机模式进行测试时，使用默认配置既可</p>
</li>
<li><p>配置ZooKeeper环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>添加相关路径</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ZooKeeper</span></span><br><span class="line"><span class="built_in">export</span> ZOOKEEPER_HOME=/usr/<span class="built_in">local</span>/zookeeper </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$ZOOKEEPER_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<p>并使之生效</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动ZooKeeper</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zookeeper                          # 进入zookeeper安装文件夹</span><br><span class="line">./bin/zkServer.sh start                          # 启动zookeeper</span><br></pre></td></tr></table></figure>
<p>输入启动命令后，出现STARTED字样则说明启动成功</p>
<p><img src="G:\屏幕截图\其他组件安装部分\1.jpg" alt="1"></p>
<p>zookeeper正常启动后，能在jps中查看到QuorumPeerMain进程</p>
<p><img src="G:\屏幕截图\其他组件安装部分\2.jpg" alt="2"></p>
</li>
</ul>
<h3 id="2-Spark安装与配置"><a href="#2-Spark安装与配置" class="headerlink" title="2.Spark安装与配置"></a>2.Spark安装与配置</h3><h4 id="2-1-Scala下载与安装"><a href="#2-1-Scala下载与安装" class="headerlink" title="2.1 Scala下载与安装"></a>2.1 Scala下载与安装</h4><p>　　在安装Spark前，我们需先安装Scala，在可<strong><a href="http://www.scala-lang.org/" target="_blank" rel="noopener">Scala官网</a></strong>下载最新版本Scala，并且能够查阅版本改动说明，本次课程采用2.10.4版本进行安装。可以采用WinSCP传输scala-2.10.4至虚拟机“下载”文件夹中，再进行后续安装。</p>
<ul>
<li><p>Spark解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                             # 进入下载文件夹</span><br><span class="line">sudo tar -zxf scala-2.10.4.tgz -C /usr/local          # 安装至/usr/local文件夹内</span><br><span class="line">cd /usr/local                                         # 进入/usr/local文件夹</span><br><span class="line">sudo mv ./scala-2.10.4/ ./scala                       # 更名为scala</span><br><span class="line">sudo chown -R hadoop ./scala                          # 修改scala权限</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>添加scala安装路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">scala</span></span><br><span class="line">export SCALA_HOME=/usr/local/scala</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure>
<p>并保存修改</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.profile</span><br></pre></td></tr></table></figure>
<p>尝试启动scala</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scala</span><br></pre></td></tr></table></figure>
<p>能进入scala的shell界面，则说明安装成功，输入</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure>
<p>退出交互界面。</p>
</li>
</ul>
<h4 id="2-2-Spark下载"><a href="#2-2-Spark下载" class="headerlink" title="2.2 Spark下载"></a>2.2 Spark下载</h4><p>　　在<strong><a href="http://spark.apache.org/" target="_blank" rel="noopener">Spark官网</a></strong>可下载最新版本Spark，并且能够查阅版本改动说明，本次课程采用1.4.0版本进行安装。可以采用WinSCP传输spark-1.4.0-bin-hadoop2.4.tgz至虚拟机“下载”文件夹中，再进行后续安装。值得注意的是， 接在Spark版本号后面的是对应推荐的Hadoop运行版本，在企业实际应用中，如果Spark版本和对应hadoop版本不匹配，推荐安装<code>Pre-build with user-provided Hadoop</code>的Spark版本。</p>
<h4 id="2-3-Spark安装与配置"><a href="#2-3-Spark安装与配置" class="headerlink" title="2.3 Spark安装与配置"></a>2.3 Spark安装与配置</h4><ul>
<li><p>Spark解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                              # 进入下载文件夹</span><br><span class="line">sudo tar -zxf spark-1.4.0-bin-hadoop2.4.tgz -C /usr/local   # 安装至/usr/local文件夹内</span><br><span class="line">cd /usr/local                                         # 进入/usr/local文件夹</span><br><span class="line">sudo mv ./spark-1.4.0-bin-hadoop2.4/ ./spark          # 更名为spark</span><br><span class="line">sudo chown -R hadoop ./spark                          # 修改sqoop权限</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>添加spark安装路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">spark</span></span><br><span class="line">export SPARK_HOME=/usr/local/spark</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure>
<p>并保存修改</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改Spark配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark/conf                              # 进入spark配置文件夹</span><br><span class="line">sudo cp spark-env.sh.template spark-env.sh            # 复制spark-env临时文件为配置文件</span><br><span class="line">vim spark-env.sh                                      # 编辑spark配置文件</span><br></pre></td></tr></table></figure>
<p>添加下述配置信息</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=$(/usr/<span class="built_in">local</span>/hadoop/bin/hadoop classpath)</span><br></pre></td></tr></table></figure>
<p>有了上面的配置信息以后，Spark就可以把数据存储到Hadoop分布式文件系统HDFS中，也可以从HDFS中读取数据。如果没有配置上面信息，Spark就只能读写本地数据，无法读写HDFS数据。在伪分布式模式下仅测试是否安装成功时，其他配置暂时可不做修改。</p>
</li>
<li><p>测试运行</p>
<p>运行Spark自带示例，检测是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">run-example SparkPi 2&gt;&amp;1 | grep "Pi is"                # 尝试运行示例Pi，并抓取结果</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\其他组件安装部分\14.jpg" alt="14"></p>
<p>同时，可尝试运行Spark-shell</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell                                # 进入后可输入exit退出</span><br></pre></td></tr></table></figure>
<p>若想过滤每次启动的INFO信息，可进行以下设置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark/conf                   # 进入配置文件夹</span><br><span class="line">cp log4j.properties.template log4j.properties</span><br><span class="line">vim log4j.properties</span><br></pre></td></tr></table></figure>
<p>将第二行中的INFO改成WARN，保存并退出</p>
<p><img src="G:\屏幕截图\其他组件安装部分\15.jpg" alt="15"></p>
<p>再次进入spark-shell，则不会显示INFO信息了。</p>
</li>
</ul>
<h3 id="3-HBase安装与配置"><a href="#3-HBase安装与配置" class="headerlink" title="3.HBase安装与配置"></a>3.HBase安装与配置</h3><h4 id="3-1HBase下载"><a href="#3-1HBase下载" class="headerlink" title="3.1HBase下载"></a>3.1HBase下载</h4><p>　　在<strong><a href="http://hbase.apache.org/" target="_blank" rel="noopener">HBase官网</a></strong>可下载最新版本HBase，并且能够查阅版本改动说明，本次课程采用0.98.13版本进行安装。可以采用WinSCP传输hbase-0.98.13-hadoop2-bin.tar至虚拟机“下载”文件夹中，再进行后续安装。</p>
<h4 id="3-2-安装与配置"><a href="#3-2-安装与配置" class="headerlink" title="3.2 安装与配置"></a>3.2 安装与配置</h4><ul>
<li><p>HBase解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                              # 进入下载文件夹</span><br><span class="line">sudo tar -zxf hbase-0.98.13-hadoop2-bin.tar.gz -C /usr/local    # 安装至/usr/local文件夹内</span><br><span class="line">cd /usr/local                                         # 进入/usr/local文件夹</span><br><span class="line">sudo mv ./hbase-0.98.13-hadoop2/ ./hbase              # 更名为hbase</span><br><span class="line">sudo chown -R hadoop ./hbase                          # 修改hbase权限</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改HBase相关配置</p>
<ul>
<li><p>添加HBase安装路径至系统环境变量</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>添加下述路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">HBase</span></span><br><span class="line">export HBASE_HOME=/usr/local/hbase</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure>
<p>并使之生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.profile</span><br></pre></td></tr></table></figure>
<p>进而检测HBase是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase version</span><br></pre></td></tr></table></figure>
<p>若出现如下字样，则说明安装成功</p>
<p><img src="G:\屏幕截图\其他组件安装部分\3.jpg" alt="3"></p>
</li>
<li><p>采用默认配置，测试HBase是否正常运行</p>
<p>启动Hadoop集群</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh                                    # 如集群已启动，则忽略此步</span><br><span class="line">start-hbase.sh                                  # 启动HBase</span><br><span class="line">hbase shell                                     # 进入hbase的shell交互界面</span><br></pre></td></tr></table></figure>
<p>出现下述情况，则说明启动成功</p>
<p><img src="G:\屏幕截图\其他组件安装部分\4.jpg" alt="4"></p>
<p>在shell界面中，输入help可查看HBase相关命令，输入exit则可退出。关于HBase的数据基本操作，详见附录三。</p>
</li>
<li><p>停止运行hbase</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-hbase.sh</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
</li>
</ul>
<h3 id="4-Hive安装与配置"><a href="#4-Hive安装与配置" class="headerlink" title="4.Hive安装与配置"></a>4.Hive安装与配置</h3><h4 id="4-1Hive下载"><a href="#4-1Hive下载" class="headerlink" title="4.1Hive下载"></a>4.1Hive下载</h4><p>　　在<strong><a href="https://hive.apache.org/" target="_blank" rel="noopener">Hive官网</a></strong>可下载最新版本Hive，并且能够查阅版本改动说明，本次课程采用2.1.1版本进行安装。可以采用WinSCP传输apache-hive-2.1.1-bin.tar至虚拟机“下载”文件夹中，再进行后续安装。</p>
<h4 id="4-2-安装与配置"><a href="#4-2-安装与配置" class="headerlink" title="4.2 安装与配置"></a>4.2 安装与配置</h4><ul>
<li><p>Hive解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                              # 进入下载文件夹</span><br><span class="line">sudo tar -zxf apache-hive-2.1.1-bin.tar.gz -C /usr/local    # 安装至/usr/local文件夹内</span><br><span class="line">cd /usr/local                                         # 进入/usr/local文件夹</span><br><span class="line">sudo mv ./apache-hive-2.1.1-bin/ ./hive               # 更名为hive</span><br><span class="line">sudo chown -R hadoop ./hive                           # 修改hive权限</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装MySQL</p>
<p>  由于Hive需要数据库存储元数据（用来存储数据库中数据主属性信息），且只有以MySQL为元数据库时才能开启分布式，因此我们需要在Ubuntu中安装MySQL。</p>
<ul>
<li><p>利用apt-get安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update                          #更新软件源</span><br><span class="line">sudo apt-get install mysql-server            #安装mysql</span><br></pre></td></tr></table></figure>
<p>安装过程会提示设置MySQL中root用户密码，根据自身喜好设置既可</p>
</li>
<li><p>启动MySQL</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mysql start                       # 关闭MySQL把start改成stop既可</span><br></pre></td></tr></table></figure>
<p>使用下述命令验证MySQL是否成功启动</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netstat -tap | grep mysql</span><br></pre></td></tr></table></figure>
<p>端口处于listen状态则说明启动成功</p>
<p><img src="G:\屏幕截图\其他组件安装部分\11.jpg" alt="11"></p>
</li>
<li><p>进入MySQL Shell界面</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure>
<p>然后输入刚才设置的root密码既可</p>
</li>
<li><p>更改配置</p>
<p>在默认状态下，是无法利用Sqoop向MySQL中导入中文的，在mysql交互界面输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &quot;char%&quot;;</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\其他组件安装部分\12.jpg" alt="12"></p>
<p>可以看到，character_set_server默认是latin1</p>
<p>因此需要修改部分配置，首先在MySQL交互界面输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit;</span><br></pre></td></tr></table></figure>
<p>退出，然后进入配置文件编辑环境</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/mysql/                                     # 进入配置文件夹</span><br><span class="line">sudo vim my.cnf                                    # 修改配置文件</span><br></pre></td></tr></table></figure>
<p>Basic Settings中加入一行</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">character_set_server=utf8</span><br></pre></td></tr></table></figure>
<p>保存退出，并重启MySQL服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mysql restart</span><br></pre></td></tr></table></figure>
<p>登录MySQL</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure>
<p>查看当前设置编码</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &quot;char%&quot;;</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\其他组件安装部分\13.jpg" alt="13"></p>
<p>已更改成功，退出MySQL，关闭MySQL服务</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit;</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service mysql stop</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
</li>
<li><p>修改Hive相关配置</p>
<ul>
<li><p>添加Hive安装路径至系统环境变量</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>添加下述路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">Hive</span></span><br><span class="line">export HIVE_HOME=/usr/local/hive</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>
<p>并使之生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.profile</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hive/conf                              # 进入配置文件夹</span><br><span class="line">cp hive-default.xml.template hive-default.xml        # 复制配置临时文件为配置文件</span><br><span class="line">vim hive-site.xml                                 # 创建并修改其他配置文件</span><br></pre></td></tr></table></figure>
<p>写入下述配置信息</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span><br><span class="line">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
<li><p>配置MySQL为元数据库</p>
<p>拷贝JDBC包至HIVE_HOME/lib中，JDBC包的下载参考前述部分</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载</span><br><span class="line">cp mysql-connector-java-5.1.26-bin.jar /usr/local/hive/lib</span><br></pre></td></tr></table></figure>
<p>启动MySQL服务，并登录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service mysql start                    # 启动mysql服务</span><br><span class="line">mysql -u root -p                       # 登陆shell界面</span><br></pre></td></tr></table></figure>
<p>新建hive数据库，来保存元数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database hive;    # 此hive数据库与hive-site.xml中localhost:3306/hive的hive对应，用来保存hive元数据</span><br></pre></td></tr></table></figure>
<p>配置MySQL允许hive接入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">grant all on *.* to hive@localhost identified by &apos;hive&apos;;   # 将所有数据库的所有表的所有权限赋给hive用户，后面的hive是配置hive-site.xml中配置的连接密码</span><br><span class="line">flush privileges;          # 刷新mysql系统权限关系表</span><br><span class="line">exit;                      # 退出MySQL</span><br></pre></td></tr></table></figure>
<p>启动hive</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh                                 # 先启动集群</span><br><span class="line">schematool -dbType mysql -initSchema         # 首次启动hive2，需要初始化元数据库</span><br><span class="line">hive                                         # 启动hive</span><br></pre></td></tr></table></figure>
<p>进入hive界面，则说明安装成功，同时，输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit;</span><br></pre></td></tr></table></figure>
<p>既可退出shell界面。</p>
</li>
</ul>
</li>
</ul>
<h3 id="5-Sqoop安装与配置"><a href="#5-Sqoop安装与配置" class="headerlink" title="5.Sqoop安装与配置"></a>5.Sqoop安装与配置</h3><h4 id="5-1-Sqoop下载"><a href="#5-1-Sqoop下载" class="headerlink" title="5.1 Sqoop下载"></a>5.1 Sqoop下载</h4><p>　　在<strong><a href="http://sqoop.apache.org/" target="_blank" rel="noopener">Sqoop官网</a></strong>可下载最新版本sqoop，并且能够查阅版本改动说明，本次课程采用1.4.6版本进行安装。可以采用WinSCP传输sqoopr-1.4.6.tar至虚拟机“下载”文件夹中，再进行后续安装。也可尝试使用wget命令直接在官网进行下载，使用命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/1.4.6/sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz</span><br></pre></td></tr></table></figure>
<h4 id="5-2-Sqoop安装与配置"><a href="#5-2-Sqoop安装与配置" class="headerlink" title="5.2 Sqoop安装与配置"></a>5.2 Sqoop安装与配置</h4><ul>
<li><p>Sqoop解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                              # 进入下载文件夹</span><br><span class="line">sudo tar -zxf sqoop-1.4.6.bin__hadoop-2.0.4-alpha.tar.gz -C /usr/local    # 安装至/usr/local文件夹内</span><br><span class="line">cd /usr/local                                         # 进入/usr/local文件夹</span><br><span class="line">sudo mv ./sqoop-1.4.6.bin__hadoop-2.0.4-alpha/ ./sqoop                   # 更名为sqoop</span><br><span class="line">sudo chown -R hadoop ./sqoop                          # 修改sqoop权限</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改Sqoop配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/sqoop/conf                              # 进入sqoop配置文件夹</span><br><span class="line">sudo cp sqoop-env-template.sh sqoop-env.sh            # 复制sqoop-env临时文件为配置文件</span><br><span class="line">vim sqoop-env.sh                                      # 编辑sqoop配置文件</span><br></pre></td></tr></table></figure>
<p>对文件中下述路径进行修改</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Set path to where bin/hadoop is available</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#Set path to where hadoop-*-core.jar is available</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"></span><br><span class="line"><span class="comment">#set the path to where bin/hbase is available</span></span><br><span class="line"><span class="built_in">export</span> HBASE_HOME=/usr/<span class="built_in">local</span>/hbase</span><br><span class="line"></span><br><span class="line"><span class="comment">#Set the path to where bin/hive is available</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/hive</span><br><span class="line"></span><br><span class="line"><span class="comment">#Set the path for where zookeper config dir is</span></span><br><span class="line"><span class="built_in">export</span> ZOOCFGDIR=/usr/<span class="built_in">local</span>/zookeeper</span><br></pre></td></tr></table></figure>
<p>配置环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.profile</span><br></pre></td></tr></table></figure>
<p>添加下述路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export SQOOP_HOME=/usr/local/sqoop</span><br><span class="line">export PATH=$PATH:$SBT_HOME/bin:$SQOOP_HOME/bin</span><br><span class="line">export CLASSPATH=$CLASSPATH:$SQOOP_HOME/lib</span><br></pre></td></tr></table></figure>
<p>并使之生效</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>由于Sqoop采用JDBC进行数据传输，因此我们还需要MySQL驱动包拷贝到Sqoop安装文件中的lib文件夹内。首先利用WinSCP将准备好的<code>mysql-connector-java-5.1.38</code>文件拷贝至下载文件夹，也可在<strong><a href="https://www.mysql.com/products/connector/" target="_blank" rel="noopener">MySQL官网对应位置</a></strong>进行下载，若是官网下载，则还需要先解压，后拷贝jar包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载</span><br><span class="line">sudo cp mysql-connector-java-5.1.26-bin.jar /usr/local/sqoop/lib/  # 拷贝jar包至Sqoop中lib文件夹内</span><br></pre></td></tr></table></figure>
<p>接下来尝试与MySQL连接</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service mysql start</span><br><span class="line">sqoop list-databases --connect jdbc:mysql://127.0.0.1:3306/ --username root -P</span><br></pre></td></tr></table></figure>
<p>出现databases的list则说明配置安装成功</p>
<p><img src="G:\屏幕截图\其他组件安装部分\19.jpg" alt="19"></p>
</li>
</ul>
<h3 id="6-Zeppelin安装与配置"><a href="#6-Zeppelin安装与配置" class="headerlink" title="6.Zeppelin安装与配置"></a>6.Zeppelin安装与配置</h3><h4 id="6-1-Zeppelin下载"><a href="#6-1-Zeppelin下载" class="headerlink" title="6.1 Zeppelin下载"></a>6.1 Zeppelin下载</h4><p>　　在<strong><a href="http://zeppelin.apache.org/" target="_blank" rel="noopener">Zeppelin官网</a></strong>可下载最新版本Zeppelin，并且能够查阅版本改动说明，本次课程采用0.6.0版本进行安装。可以采用WinSCP传输zeppelin-0.6.0-bin-all至虚拟机“下载”文件夹中，再进行后续安装。</p>
<h4 id="6-2-Zeppelin安装与配置"><a href="#6-2-Zeppelin安装与配置" class="headerlink" title="6.2 Zeppelin安装与配置"></a>6.2 Zeppelin安装与配置</h4><ul>
<li><p>Zeppelin解压安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~/下载                                                # 进入下载文件夹</span><br><span class="line">sudo tar -zxf zeppelin-0.6.0-bin-all.tgz -C /usr/local   # 安装至/usr/local文件夹内</span><br><span class="line">cd /usr/local                                            # 进入/usr/local文件夹</span><br><span class="line">sudo mv ./zeppelin-0.6.0-bin-all/ ./zeppelin             # 更名为zeppelin</span><br><span class="line">sudo chown -R hadoop ./zeppelin                          # 修改zeppelin权限</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改Zeppelin-env配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zeppelin/conf                       # 进入zeppelin配置文件夹</span><br><span class="line">cp zeppelin-env.sh.template zeppelin-env.sh       # 复制zeppelin-env临时文件为配置文件</span><br><span class="line">vim zeppelin-env.sh                               # 编辑zeppelin配置文件</span><br></pre></td></tr></table></figure>
<p>对文件中下述内容进行修改</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#java</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"><span class="comment">#hadoop</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIF=/usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line"><span class="comment">#spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="comment">#hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/hive</span><br><span class="line"><span class="comment">#python</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=/usr/bin/python</span><br><span class="line"><span class="built_in">export</span> PYTHON_HOME=/usr/bin/python</span><br><span class="line"><span class="comment">#Scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/scala</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SCALA_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<p>保存并退出</p>
</li>
<li><p>修改Zeppelin-site配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zeppelin/conf                       # 进入zeppelin配置文件夹</span><br><span class="line">cp zeppelin-site.xml.template zeppelin-site.xml   # 复制zeppelin-site临时文件为配置文件</span><br><span class="line">vim zeppelin-site.xml                             # 编辑zeppelin配置文件</span><br></pre></td></tr></table></figure>
<p>此处暂时只修改端口，避免冲突</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>zeppelin.server.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>18080<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Server port.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>测试启动Zeppelin</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh                                       # 启动hadoop相关进程</span><br><span class="line">/usr/local/spark/sbin/start-all.sh                 # 启动spark相关进程</span><br><span class="line">/usr/local/zeppelin/bin/zeppelin-daemon.sh start   # 启动Zeppelin</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\其他组件安装部分\16.jpg" alt="16"></p>
<p>然后在虚拟机中打开火狐浏览器，输入<a href="http://local:18080查看Zeppelin界面" target="_blank" rel="noopener">http://local:18080查看Zeppelin界面</a></p>
<p><img src="G:\屏幕截图\其他组件安装部分\19.jpg" alt="19"></p>
<p>  创建Test Note 1测试伪分布式模式下Zeppelin能否正常工作</p>
<p><img src="G:\屏幕截图\其他组件安装部分\20.jpg" alt="20"></p>
<p>点击创建，进入Note界面，在默认Spark的命令行中测试能否正常使用</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc.master</span><br></pre></td></tr></table></figure>
<p>若能正常显示结果，则说明能安装配置成功</p>
<p><img src="G:\屏幕截图\其他组件安装部分\21.jpg" alt="21"></p>
</li>
</ul>
<h2 id="四、Hadoop分布式集群安装与配置"><a href="#四、Hadoop分布式集群安装与配置" class="headerlink" title="四、Hadoop分布式集群安装与配置"></a>四、Hadoop分布式集群安装与配置</h2><p>　　接下来，正式进入集群安装模式，为了减少工作量，我们将在之前配置好的伪分布式虚拟机的基础上，利用复制克隆虚拟机的方式进行分布式集群的安装部署。同样，我们将在附录中给出基于CentOS系统分布式集群安装部署方法，此处仍然以Ubuntu系统为例进行安装。</p>
<h3 id="1-复制虚拟机"><a href="#1-复制虚拟机" class="headerlink" title="1.复制虚拟机"></a>1.复制虚拟机</h3><p>打开VirtualBox，在虚拟机关闭状态下，右键选中之前安装好的伪分布式虚拟机Ubuntu，选择复制</p>
<p><img src="G:\屏幕截图\分布式集群安装部分\1.jpg" alt="1"></p>
<p>输入复制后的虚拟机名称，接下来要复制三台虚拟机用作分布式集群搭建，此处以slave1位例，后面二者操作类似。最好勾选重置MAC地址，然后点击下一步。</p>
<p><img src="G:\屏幕截图\分布式集群安装部分\2.jpg" alt="2"></p>
<p>选择完全复制，点击复制，等待复制完成</p>
<p><img src="G:\屏幕截图\分布式集群安装部分\3.jpg" alt="3"></p>
<p>复制完成后，先进入slave1进行相关设置，选择slave1虚拟机，点击启动</p>
<p><img src="G:\屏幕截图\分布式集群安装部分\4.jpg" alt="4"></p>
<h3 id="2-设置slave1虚拟机"><a href="#2-设置slave1虚拟机" class="headerlink" title="2.设置slave1虚拟机"></a>2.设置slave1虚拟机</h3><p>启动虚拟机后，仍然以hadoop用户进行登录。</p>
<h4 id="2-1-配置虚拟机网络"><a href="#2-1-配置虚拟机网络" class="headerlink" title="2.1 配置虚拟机网络"></a>2.1 配置虚拟机网络</h4><p>在虚拟机内进入命令行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/network/interfaces</span><br></pre></td></tr></table></figure>
<p>进入编辑模式，输入下述内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NAT interface</span></span><br><span class="line">auto eth0</span><br><span class="line">iface eth0 inet dhcp                         <span class="comment"># 网卡1是NAT模式，采用动态分配方式自动获取ip</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># host only interface</span></span><br><span class="line">auto eth1</span><br><span class="line">iface eth1 inet static                       <span class="comment"># 网卡2是仅主机模式，用于建立内部网络，设置静态IP</span></span><br><span class="line">address         192.168.56.102               <span class="comment"># 注意，此处从102开始，101分配给master，100分配给伪分布式</span></span><br><span class="line">netmask         255.255.255.0</span><br><span class="line">network         192.168.56.0</span><br><span class="line">broadcast       192.168.56.255</span><br></pre></td></tr></table></figure>
<p>保存并退出</p>
<h4 id="2-2-设置hostname"><a href="#2-2-设置hostname" class="headerlink" title="2.2 设置hostname"></a>2.2 设置hostname</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hostname</span><br></pre></td></tr></table></figure>
<p>在弹出的对话框中删除原有内容，输入slave1，保存并退出</p>
<p><img src="G:\屏幕截图\分布式集群安装部分\5.jpg" alt="5"></p>
<h4 id="2-3-设置hosts映射"><a href="#2-3-设置hosts映射" class="headerlink" title="2.3 设置hosts映射"></a>2.3 设置hosts映射</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/hosts</span><br></pre></td></tr></table></figure>
<p>保持文件内原有内容<strong>不变</strong>，另起一行输入下述内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.56.101     master</span><br><span class="line">192.168.56.102     slave1</span><br><span class="line">192.168.56.103     slave2</span><br></pre></td></tr></table></figure>
<p><img src="G:\屏幕截图\分布式集群安装部分\6.jpg" alt="6"></p>
<p>保存并退出。</p>
<h4 id="2-4-更改Hadoop相关配置"><a href="#2-4-更改Hadoop相关配置" class="headerlink" title="2.4 更改Hadoop相关配置"></a>2.4 更改Hadoop相关配置</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hadoop/etc/hadoop                      # 进入配置文件夹</span><br></pre></td></tr></table></figure>
<ul>
<li><p>更改core-site.xml相关配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>
<p>将localhost更改为master</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>更改hdfs-site.xml相关配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>
<p>进行以下更改</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>更改mapred-site.xml相关配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure>
<p>进行以下更改</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>更改yarn-site.xml相关配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>
<p>进行以下更改</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>更改slaves相关配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim slaves</span><br></pre></td></tr></table></figure>
<p>在此文件中填写作为slave节点的host名称</p>
<p>删除原有内容，输入</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure>
<p>保存并退出</p>
<p><img src="G:\屏幕截图\分布式集群安装部分\7.jpg" alt="7"></p>
</li>
</ul>
<h4 id="2-5-更改Spark相关配置"><a href="#2-5-更改Spark相关配置" class="headerlink" title="2.5 更改Spark相关配置"></a>2.5 更改Spark相关配置</h4><ul>
<li><p>修改spark-env.sh相关配置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/spark/conf                       # 进入Spark配置文件夹</span><br><span class="line">vim spark-env.sh</span><br></pre></td></tr></table></figure>
<p>添加下列内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#java</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386</span><br><span class="line"><span class="comment">#scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/scala</span><br><span class="line"><span class="comment">#hadoop</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> YARN_CONF_DIR=/usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line"><span class="comment">#hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/hive</span><br><span class="line"><span class="built_in">export</span> HIVE_CONF_DIR=/usr/<span class="built_in">local</span>/hive/conf</span><br><span class="line"><span class="comment">#spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> SPARK_LOCAL_DIRS=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=$(/usr/<span class="built_in">local</span>/hadoop/bin/hadoop classpath)</span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_CORES=1</span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_INSTANCES=1 </span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_MEMORY=1g</span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_IP=master</span><br><span class="line"><span class="built_in">export</span> SPARK_LIBRARY_PATH=.:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JAVA_HOME</span>/jre/lib:<span class="variable">$HADOOP_HOME</span>/lib/native</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改slaves文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp slaves.template slaves</span><br><span class="line">vim slaves</span><br></pre></td></tr></table></figure>
<p>和Hadoop中slaves设置一样，输入作为slaves的节点名称</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure>
<p>保存并退出</p>
</li>
</ul>
<h4 id="2-6-更改ZooKeeper相关配置"><a href="#2-6-更改ZooKeeper相关配置" class="headerlink" title="2.6 更改ZooKeeper相关配置"></a>2.6 更改ZooKeeper相关配置</h4><ul>
<li><p>修改zoo.cfg文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zookeeper/conf</span><br><span class="line">vim zoo.cfg</span><br></pre></td></tr></table></figure>
<p>修改dataDir指向</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDir=/usr/<span class="built_in">local</span>/zookeeper/data</span><br></pre></td></tr></table></figure>
<p>在配置文件最低端增加各节点服务标识</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server.0=master:2888:3888  </span><br><span class="line">server.1=slave1:2888:3888  </span><br><span class="line">server.2=slave2:2888:3888</span><br></pre></td></tr></table></figure>
<p>其中，server.x为服务机器标识，2888和3888为端口号。保存并退出</p>
</li>
<li><p>创建指向文件夹及标识文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zookeeper</span><br><span class="line">mkdir data</span><br><span class="line">cd data</span><br><span class="line">vim myid</span><br></pre></td></tr></table></figure>
<p>在打开文本中输入1，用来标识本机服务</p>
</li>
</ul>
<h4 id="2-7-更改HBase相关配置"><a href="#2-7-更改HBase相关配置" class="headerlink" title="2.7 更改HBase相关配置"></a>2.7 更改HBase相关配置</h4><ul>
<li><p>修改hbase-env.sh文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hbase/conf</span><br><span class="line">vim hbase-env.sh</span><br></pre></td></tr></table></figure>
<p>添加下述内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#java</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/lib/jvm/java-7-openjdk-i386</span><br><span class="line"><span class="comment">#spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="comment">#zookeeper</span></span><br><span class="line"><span class="built_in">export</span> HBASE_MANAGERS_ZK=ture</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改hbase-site.xml文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hbase-site.xml</span><br></pre></td></tr></table></figure>
<p>添加下述内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">   <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>####2.8 其他组件更改</p>
<ul>
<li><p>sqoop</p>
<p>对于sqoop而言，只需要在NameNode上安装即可，此处暂不做修改</p>
</li>
<li><p>hive</p>
<p>只需要修改site中MySQL连接IP即可</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hive/conf</span><br><span class="line">vim hive-site.xml</span><br></pre></td></tr></table></figure>
<p>将localhost改为master</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>JDBC connect string for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>Driver class name for a JDBC metastore<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>username to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hive<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">description</span>&gt;</span>password to use against metastore database<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>zeppelin</p>
<p>需要在zeppelin-env.sh文件中添加master路径</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/zeppelin/conf</span><br><span class="line">vim zeppelin-env.sh</span><br></pre></td></tr></table></figure>
<p>加入下述内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> MASTER=spark://192.168.56.101:7077</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-复制slave1"><a href="#3-复制slave1" class="headerlink" title="3.复制slave1"></a>3.复制slave1</h3><p>关闭虚拟机，安装前述方法复制slave1，分别命名为master和slave2，然后分别打开复制好的两个虚拟机，更改其hostname和interface，更改完毕后重启这两个虚拟机，并打开之前配好的slave1，准备建立节点间免密登录。同时，记得更改myid本机标识，master为0，slave2为2.</p>
<p>###4.配置各节点免密码登录</p>
<p>利用Xshell连接三台虚拟机，然后再Xshell中继续进行操作。</p>
<p><img src="G:\屏幕截图\分布式集群安装部分\8.jpg" alt="8"></p>
<ul>
<li><p>检查节点间通信</p>
<p>在主节点上输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ping slave1</span><br><span class="line">ping slave2</span><br></pre></td></tr></table></figure>
<p>在其他节点上进行类似操作，使用control+c断开连接检测</p>
</li>
<li><p>检查主节点公钥</p>
<p>在主节点上输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/.ssh</span><br><span class="line">ll</span><br></pre></td></tr></table></figure>
<p>若有id_rsa（私钥）及id_rsa.pub（公钥），则继续进行下一步操作（之前配置过ssh，因此公私钥已经生成）</p>
</li>
<li><p>将主节点公钥传输至两个子节点中</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp ~/.ssh/id_rsa.pub hadoop@slave1:~/下载</span><br><span class="line">scp ~/.ssh/id_rsa.pub hadoop@slave2:~/下载</span><br></pre></td></tr></table></figure>
</li>
<li><p>在子节点中将主节点公钥加入授权</p>
<p>分别在两个子节点中进行操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat ~/下载/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">rm -rf ~/下载/id_rsa.pub                            # 用完即删</span><br></pre></td></tr></table></figure>
</li>
<li><p>测试主节点能否ssh连接子节点</p>
<p>在主节点中输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh slave1</span><br><span class="line">exit</span><br><span class="line">ssh slave2 </span><br><span class="line">exit</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="5-启动集群"><a href="#5-启动集群" class="headerlink" title="5.启动集群"></a>5.启动集群</h3><p>至此，全部配置完毕，准备启动集群，并检测集群是否能正常运行。</p>
<p>在主节点上执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br><span class="line">start-all.sh</span><br></pre></td></tr></table></figure>
<p>查看各节点jps，是否正常运行</p>
<p>接着测试Spark集群，在主节点上输入</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/spark/sbin/start-all.sh</span><br></pre></td></tr></table></figure>
<p>接着进入hive和HBase交互界面，测试能否正常运行</p>
<p>##附录一：Linux基本操作指令</p>
<p>###1、查看当前目录下的内容：ls</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls</span><br><span class="line">ls -l</span><br><span class="line">ls -l -a                                      # 查看隐藏文件/夹</span><br></pre></td></tr></table></figure>
<p>###2、进入到指令的文件夹内：cd</p>
<p>   说明：$符号前是~，说明当前是位于用户主目录下(/home/hduser)</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /		                                   # 进入到文件系统根目录</span><br><span class="line">cd usr                                         # 进入到当前目录下的usr目录(相对目录)</span><br><span class="line">cd /home/hduser                                # 进入到用户主目录(以/开头，是绝对目录)</span><br><span class="line">cd ..	                                       # 进入到当前目录的上一级目录</span><br><span class="line">cd ~		                                   # 进入到用户主目录</span><br></pre></td></tr></table></figure>
<h3 id="3-创建文件夹：mkdir"><a href="#3-创建文件夹：mkdir" class="headerlink" title="3.创建文件夹：mkdir"></a>3.创建文件夹：mkdir</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir a	                                       # 创建文件夹a</span><br></pre></td></tr></table></figure>
<p>###4.修改文件夹：mv</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv a b                                          # 更名a为b</span><br></pre></td></tr></table></figure>
<p>###5.删除文件夹：rm</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -r b                                         # 删除文件夹b</span><br></pre></td></tr></table></figure>
<p>###6.创建文件：touch</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">touch a.txt                                      # 创建txt格式文件a</span><br></pre></td></tr></table></figure>
<p>###7.编辑文件：gedit</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gedit a.txt                                       # 编辑文件a</span><br></pre></td></tr></table></figure>
<p>###8.查看文件内容：cat</p>
 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat a.txt</span><br></pre></td></tr></table></figure>
<p>###9.拷贝文件或文件夹：cp</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">touch a.data </span><br><span class="line">cp a.data b.data</span><br></pre></td></tr></table></figure>
<p>###11.清屏命令：clear</p>
<h2 id="附录二：HDFS基本操作指令"><a href="#附录二：HDFS基本操作指令" class="headerlink" title="附录二：HDFS基本操作指令"></a>附录二：HDFS基本操作指令</h2><h3 id="1-HDFS的shell命令方式"><a href="#1-HDFS的shell命令方式" class="headerlink" title="1.HDFS的shell命令方式"></a>1.HDFS的shell命令方式</h3><p>​        即使用HDFS操作语句的关键字</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs         <span class="comment"># 适用于任何不同的文件系统，包括本地文件系统和HDFS文件系统</span></span><br><span class="line">hadoop dfs        <span class="comment"># 只能适用HDFS文件系统</span></span><br><span class="line">hdfs dfs          <span class="comment"># 同hadoop dfs</span></span><br></pre></td></tr></table></figure>
<p>​        在实际操作过程使用何种指令可因人而异，出于习惯考虑下列操作实例均以<code>hadoop fs</code>关键字开头。</p>
<ul>
<li><p>注：可使用以下命令查看总共支持哪些命令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs</span><br></pre></td></tr></table></figure>
</li>
<li><p>注：使用help命令可查看具体命令使用方法</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -<span class="built_in">help</span> put</span><br></pre></td></tr></table></figure>
</li>
<li><p>另外，可使用web对HDFS文件系统实施监控。</p>
</li>
</ul>
<h3 id="2-创建HDFS目录"><a href="#2-创建HDFS目录" class="headerlink" title="2.创建HDFS目录"></a>2.创建HDFS目录</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /user                <span class="comment"># 创建user目录</span></span><br><span class="line">hadoop fs -mkdir /user/root           <span class="comment"># 创建user子目录</span></span><br><span class="line">hadoop fs -mkdir /user/root/<span class="built_in">test</span>      <span class="comment"># 创建root子目录</span></span><br><span class="line">hadoop fs -mkdir -p /dir1/dir2/dir3   <span class="comment"># 同时创建多级子目录</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-查看HDFS目录"><a href="#3-查看HDFS目录" class="headerlink" title="3.查看HDFS目录"></a>3.查看HDFS目录</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls                         <span class="comment"># 列出当前用户下的所有目录</span></span><br><span class="line">hadoop fs -ls /                       <span class="comment"># 列出当前用户下的文件</span></span><br><span class="line">hadoop fs -ls /user                   <span class="comment"># 列出user下所有目目录</span></span><br><span class="line">hadoop fs -ls /user/root              <span class="comment"># 列出root下所有目录</span></span><br><span class="line">hadoop fs -ls -R /                    <span class="comment"># 同时列出全部子目录</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="4-复制本地文件到HDFS"><a href="#4-复制本地文件到HDFS" class="headerlink" title="4.复制本地文件到HDFS"></a>4.复制本地文件到HDFS</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<ul>
<li><p>复制本地文件README.txt到HDFS文件系统的test目录下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal /usr/<span class="built_in">local</span>/hadoop/README.txt /user/root/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>当文件已经存在时，可强制复制，作用相当于复制并替换</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal -f /usr/<span class="built_in">local</span>/hadoop/README.txt /user/root/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>同时复制多个文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal /usr/<span class="built_in">local</span>/hadoop/NOTICE.txt /usr/<span class="built_in">local</span>/hadoop/NOTICE.txt /user/root/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>复制目录到HDFS目录</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyFromLocal /usr/<span class="built_in">local</span>/hadoop/etc /user/root/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="5-使用put命令复制本地文件到HDFS"><a href="#5-使用put命令复制本地文件到HDFS" class="headerlink" title="5.使用put命令复制本地文件到HDFS"></a>5.使用put命令复制本地文件到HDFS</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<ul>
<li><p>将原本显示在屏幕上的内容存储到HDFS文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span>  abc | hadoop fs -put - /user/root/<span class="built_in">test</span>/echoin.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>将本地目录列表存储到HDFS文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /usr/<span class="built_in">local</span>/hadoop | hadoop fs -put -/user/root/<span class="built_in">test</span>/hadooplist.txt</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="6-列出HDFS目录下文件内容"><a href="#6-列出HDFS目录下文件内容" class="headerlink" title="6.列出HDFS目录下文件内容"></a>6.列出HDFS目录下文件内容</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<ul>
<li><p>显示HDFS文件目录下README.txt文件内容</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /user/root/<span class="built_in">test</span>/README.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>一页页显示</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /user/root/<span class="built_in">test</span>/README.txt|more</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="7-使用copy命令复制HDFS至本地"><a href="#7-使用copy命令复制HDFS至本地" class="headerlink" title="7.使用copy命令复制HDFS至本地"></a>7.使用copy命令复制HDFS至本地</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<ul>
<li><p>将hadooplist.txt文件复制到本地当前文件夹内</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal /user/root/<span class="built_in">test</span>/hadooplist.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>将etc文件目录复制到本地当前文件夹内</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -copyToLocal /user/root/<span class="built_in">test</span>/etc</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="8-使用get命令复制HDFS文件至本地"><a href="#8-使用get命令复制HDFS文件至本地" class="headerlink" title="8.使用get命令复制HDFS文件至本地"></a>8.使用get命令复制HDFS文件至本地</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<p>将HDFS文件复制到当前文件夹内并命名</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get /user/root/<span class="built_in">test</span>/README.txt localREADME.txt</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="9-复制HDFS文件"><a href="#9-复制HDFS文件" class="headerlink" title="9.复制HDFS文件"></a>9.复制HDFS文件</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cp</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /user/root/<span class="built_in">test</span>/temp       <span class="comment"># 建立temp文件夹</span></span><br><span class="line">hadoop fs -cp /user/root/<span class="built_in">test</span>/README.txt /user/root/<span class="built_in">test</span>/temp <span class="comment"># 将test中文件复制到temp中</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="10-删除HDFS文件"><a href="#10-删除HDFS文件" class="headerlink" title="10.删除HDFS文件"></a>10.删除HDFS文件</h3><ul>
<li><p>基本指令</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm</span><br></pre></td></tr></table></figure>
</li>
<li><p>实例</p>
<ul>
<li><p>删除文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm /user/root/<span class="built_in">test</span>/README.txt   <span class="comment"># 删除README文件</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>删除目录</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm -R /user/root/<span class="built_in">test</span>/etc     <span class="comment"># 删除etc目录</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p>##附录三：打包编译MapReduce程序</p>
<p>通常来说，运行MapReduce程序有两种方法，其一是在命令行中手动编译并打包运行，另一种则是使用Eclipse编译运行MapReduce程序，考虑到能够看到运行过程，此处介绍较为原始的命令行打包运行MapReduce方法。其中java算法代码采用MapReduce自带实例WordCount。</p>
<h3 id="1-下载源码"><a href="#1-下载源码" class="headerlink" title="1.下载源码"></a>1.下载源码</h3><p>​        由于要使用MapReduce源码中的算法代码，因此需要下载Hadoop源码。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line">mkdir WordCount                       <span class="comment"># 作为运行WordCount的工作空间</span></span><br><span class="line"><span class="built_in">cd</span> WordCount</span><br><span class="line">wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.2.0/hadoop-2.2.0-src.tar.gz</span><br></pre></td></tr></table></figure>
<p>​        下载完成后，将java文件WordCount放至工作空间</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf hadoop-2.2.0-src.tar.gz</span><br><span class="line"><span class="built_in">cd</span> hadoop-2.7.3-src/hadoop-mapreduce-project/hadoop-mapreduce-examples/src/main/java/org/apache/hadoop/examples</span><br><span class="line">ll                    <span class="comment"># 查看所有自带算法java文件</span></span><br><span class="line">cp WordCount.java ~/WordCount</span><br></pre></td></tr></table></figure>
<ul>
<li><p>附：<strong>Hadoop 2.7.3中WordCount.java源码</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information</span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"> * "License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"> * limitations under the License.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">package</span> org.apache.hadoop.examples;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span> </span></span><br><span class="line"><span class="class">       <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line">      </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                    )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</span><br><span class="line">      <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        word.set(itr.nextToken());</span><br><span class="line">        context.write(word, one);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span> </span></span><br><span class="line"><span class="class">       <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, </span></span></span><br><span class="line"><span class="function"><span class="params">                       Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                       )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">        sum += val.get();</span><br><span class="line">      &#125;</span><br><span class="line">      result.set(sum);</span><br><span class="line">      context.write(key, result);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">    <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">      System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;"</span>);</span><br><span class="line">      System.exit(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Job job = Job.getInstance(conf, <span class="string">"word count"</span>);</span><br><span class="line">    job.setJarByClass(WordCount.class);</span><br><span class="line">    job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">    job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">    job.setReducerClass(IntSumReducer.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">      FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[i]));</span><br><span class="line">    &#125;</span><br><span class="line">    FileOutputFormat.setOutputPath(job,</span><br><span class="line">      <span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]));</span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
<h3 id="2-将依赖jar包放入路径"><a href="#2-将依赖jar包放入路径" class="headerlink" title="2.将依赖jar包放入路径"></a>2.将依赖jar包放入路径</h3><ul>
<li><p>查看Hadoop所需jar包</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop classpath</span><br></pre></td></tr></table></figure>
</li>
<li><p>将Hadoop全部classpath放入路径</p>
<p>​        Hadoop文件中自带所需jar包，需要将这些jar包路径变量添加如CLASSPATH中才能运行自己编译的MapReduce程序。</p>
<p>​        修改环境变量：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>​        在打开对话框中添加CLASSPATH变量值：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> CLASSPATH=$(<span class="variable">$HADOOP_HOME</span>/bin/hadoop classpath):<span class="variable">$CLASSPATH</span></span><br></pre></td></tr></table></figure>
<p>​        使之生效：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="3-运行WordCount-java"><a href="#3-运行WordCount-java" class="headerlink" title="3.运行WordCount.java"></a>3.运行WordCount.java</h3><ul>
<li><p>编译WordCount.java</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/WordCount              </span><br><span class="line">javac WordCount.java</span><br></pre></td></tr></table></figure>
<p>编译完成后可见生成了几个.class文件。</p>
</li>
<li><p>将class文件打包成jar</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jar -cvf WordCount.jar ./WordCount*.class</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建测试文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mkdir input           <span class="comment"># 测试文件目录</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"echo of the rainbow"</span> &gt; ./input/file0</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"the waiting game"</span> &gt; ./input/file1</span><br><span class="line">ls ./input/</span><br></pre></td></tr></table></figure>
</li>
<li><p>将本地文件上传至HDFS</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rm -R /user/hadoop/<span class="built_in">test</span>/input    <span class="comment"># 存在input文件夹则删除，不存在则跳过</span></span><br><span class="line">hadoop fs -put ./input /user/root/<span class="built_in">test</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>运行WordCount</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar WordCount.jar org/apache/hadoop/examples/WordCount /user/root/<span class="built_in">test</span>/input /user/root/<span class="built_in">test</span>/output</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看运行结果</p>
<ul>
<li><p>在8088端口查看任务运行状态</p>
</li>
<li><p>在50070端口查看生成文件</p>
<p>注意到计算结果被存放至part-r-00000文件中，用cat命令可查看文件内容。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /user/root/<span class="built_in">test</span>/output/part-r-00000</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
</li>
</ul>
<p>##附录四：HBase数据基本操作</p>
<p>以下操作均在hbase shell界面中进行</p>
<h3 id="1-创建表"><a href="#1-创建表" class="headerlink" title="1.创建表"></a>1.创建表</h3><p>使用create命令创建表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create 'student','Sname','Ssex','Sage','Sdept','course'</span><br></pre></td></tr></table></figure>
<p>输出结果如下</p>
<p><img src="G:\屏幕截图\其他组件安装部分\5.jpg" alt="5"></p>
<p>此时，即创建了一个“student”表，属性有：Sname,Ssex,Sage,Sdept,course。因为HBase的表中会有一个系统默认的属性作为主键，故主键无需自行创建。创建完“student”表后，可通过describe命令查看“student”表的基本信息。</p>
<h3 id="2-添加数据"><a href="#2-添加数据" class="headerlink" title="2.添加数据"></a>2.添加数据</h3><p>HBase中用put命令添加数据，一次只能为一个表的一行数据的一个列添加一个数据。</p>
<p>执行put命令来添加主键为95001，学号为95001，名字为LiYing的一行数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">put 'student','95001','Sname:','LiYing'</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<p><img src="G:\屏幕截图\其他组件安装部分\6.jpg" alt="6"></p>
<p>执行put命令来为95001行下的course列族的math列添加了一个数据</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">put 'student','95001','course:math','80'</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<p><img src="G:\屏幕截图\其他组件安装部分\7.jpg" alt="7"></p>
<h3 id="3-查看、删除数据"><a href="#3-查看、删除数据" class="headerlink" title="3.查看、删除数据"></a>3.查看、删除数据</h3><p>HBase中有两个用于查看数据的命令：1、get命令，用于查看表的某一行数据；2、scan命令用于查看某个表的全部数据。在HBase中用delete以及deleteall命令进行删除数据操作，它们的区别是：1、delete用于删除一个数据，是put的反向操作；2、deleteall操作用于删除一行数据。</p>
<p>执行delete命令来删除student表中95001行下的Ssex列的所有版本的数据，用get命令来查看</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">delete 'student','95001','Ssex'</span><br><span class="line">get 'student','95001'</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<p><img src="G:\屏幕截图\其他组件安装部分\9.jpg" alt="9"></p>
<p>执行deleteall命令来删除student表中的95001行的全部数据，再用scan查看表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">deleteall 'student','95001'</span><br><span class="line">scan 'student'</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<p><img src="G:\屏幕截图\其他组件安装部分\10.jpg" alt="10"></p>
<p>##附录四：利用CentOS搭建分布式集群</p>
<p>下载安装虚拟机部分不再赘述，此处仅对安装好虚拟机之后的安装部分进行讲解</p>
<h2 id="一、准备CentOS-7-2"><a href="#一、准备CentOS-7-2" class="headerlink" title="一、准备CentOS 7.2"></a>一、准备CentOS 7.2</h2><h3 id="1-修改网络配置"><a href="#1-修改网络配置" class="headerlink" title="1.修改网络配置"></a>1.修改网络配置</h3><p>​        安装好CentOS系统后默认网络关闭，因此需要先开启网络服务，才能进行后续安装，开启网络服务需要修改网络配置文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/sysconfig/network-scripts/</span><br><span class="line">ls</span><br><span class="line">vi ifcfg-ens160</span><br></pre></td></tr></table></figure>
<p>修改：ONBOOT=yes</p>
<h3 id="2-安装部分需求组件"><a href="#2-安装部分需求组件" class="headerlink" title="2.安装部分需求组件"></a>2.安装部分需求组件</h3><p>​        此处安装一些常用软件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">yum -y update</span><br><span class="line">yum -y install vim</span><br><span class="line">yum -y install wget</span><br><span class="line">yum -y install epel-release</span><br><span class="line">yum -y install python-pip</span><br><span class="line">yum -y install gcc</span><br><span class="line">yum -y install gcc-c++</span><br><span class="line">yum -y install python-devel</span><br></pre></td></tr></table></figure>
<p>​</p>
<h3 id="3-验证本机无密码登陆"><a href="#3-验证本机无密码登陆" class="headerlink" title="3.验证本机无密码登陆"></a>3.验证本机无密码登陆</h3><p>​        由于后续各节点需要利用ssh协议相互通信，因此此处先配置本机能够免密码登陆。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep ssh     <span class="comment"># 验证本机是否安装SSH，一般情况下CentOS系统都已默认安装</span></span><br><span class="line">ssh localhost          <span class="comment"># 登陆到本机，需要确认yes和本机密码</span></span><br><span class="line"><span class="built_in">exit</span>                   <span class="comment"># 退出</span></span><br><span class="line"><span class="built_in">cd</span> ~/.ssh/</span><br><span class="line">ssh-keygen -t rsa      <span class="comment"># 生成密钥</span></span><br><span class="line">cat id_rsa.pub &gt;&gt; authorized_keys   <span class="comment"># 将生成公钥加入授权</span></span><br><span class="line">ssh localhost              <span class="comment"># 至此便可免密码登陆本机</span></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure>
<p>​</p>
<h3 id="4-安装java-8"><a href="#4-安装java-8" class="headerlink" title="4.安装java 8"></a>4.安装java 8</h3><ul>
<li>选择java 8版本并下载： <strong><a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">下载地址</a></strong> </li>
<li>解压并安装：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/download          <span class="comment"># 作为WinSCP传输文件的文件夹</span></span><br><span class="line"><span class="built_in">cd</span> ~/download/</span><br></pre></td></tr></table></figure>
<ul>
<li><p>利用<code>WinSCP</code>传输下载的java文件至download文件夹</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf jdk-8u131-linux-x64.tar.gz -C /usr/local</span><br><span class="line">cd /usr/local</span><br><span class="line">mv ./jdk1.8.0_131/ ./java</span><br></pre></td></tr></table></figure>
</li>
<li><p>添加java环境变量</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>​        添加下述路径： </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/java</span><br><span class="line"><span class="built_in">export</span> JRE_HOME=/usr/java/<span class="built_in">local</span>/jre</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$JRE_HOME</span>/bin</span><br><span class="line">CLASSPATH=.<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar:<span class="variable">$JRE_HOME</span>/lib</span><br><span class="line"><span class="built_in">export</span> JAVA_HOME JRE_HOME PATH CLASSPATH</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<h3 id="5-关闭防火墙"><a href="#5-关闭防火墙" class="headerlink" title="5.关闭防火墙"></a>5.关闭防火墙</h3><p>​        在配置过程中暂时关闭并设置开机不启动防火墙，在安装完毕后可重启防火墙，但如果需要安装ambari且在ambari运行过程中防火墙处于开启状态，则ambari将会报错，因此建议关闭防火墙并设置默认防火墙关闭。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld            <span class="comment"># 关闭防火墙</span></span><br><span class="line">systemctl status firewalld          <span class="comment"># 检验防火墙状态</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld         <span class="comment"># 将防火墙默认状态设置为关闭</span></span><br></pre></td></tr></table></figure>
<h3 id="6-设置SELinux"><a href="#6-设置SELinux" class="headerlink" title="6.设置SELinux"></a>6.设置SELinux</h3><p>将SELinux设置为关闭：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br></pre></td></tr></table></figure>
<p>修改：SELINUX=disabled</p>
<h3 id="7-配置ntp服务"><a href="#7-配置ntp服务" class="headerlink" title="7.配置ntp服务"></a>7.配置ntp服务</h3><p>​        ntp即为网络时间协议，由于涉及到各节点间任务调度，因此需要统一各节点时间。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntp            <span class="comment"># 安装ntp</span></span><br><span class="line">systemctl start ntpd           <span class="comment"># 开启ntp服务</span></span><br><span class="line">systemctl <span class="built_in">enable</span> ntpd          <span class="comment"># 设置默认状态为开启</span></span><br><span class="line">systemctl status ntpd          <span class="comment"># 查看ntp状态</span></span><br></pre></td></tr></table></figure>
<h3 id="8-配置httpd服务"><a href="#8-配置httpd服务" class="headerlink" title="8.配置httpd服务"></a>8.配置<code>httpd</code>服务</h3><p>​        <code>httpd</code>是Apache超文本传输协议(HTTP)服务器的主程序，由于后续可能需要配置HDP，则需要设置本地软件源，因此提前配置好<code>httpd</code>相关服务。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum -y install httpd            <span class="comment"># 安装httpd</span></span><br><span class="line">systemctl start httpd           <span class="comment"># 开启ntp服务</span></span><br><span class="line">systemctl <span class="built_in">enable</span> httpd          <span class="comment"># 设置默认状态为开启</span></span><br><span class="line">systemctl status httpd          <span class="comment"># 查看httpd状态</span></span><br></pre></td></tr></table></figure>
<p>在任意浏览器输入http://(主机地址)，若出现testing界面，则说明安装成功。</p>
<h2 id="二、安装Hadoop-2-7-3"><a href="#二、安装Hadoop-2-7-3" class="headerlink" title="二、安装Hadoop 2.7.3"></a>二、安装Hadoop 2.7.3</h2><h3 id="1-下载并安装"><a href="#1-下载并安装" class="headerlink" title="1.下载并安装"></a>1.下载并安装</h3><p>选择版本并下载：<strong><a href="https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz" target="_blank" rel="noopener">下载地址</a></strong></p>
<p>利用<code>WinSCP</code>传输下载文件至download文件夹，然后进行解压与安装：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/download</span><br><span class="line">tar -zxf hadoop-2.7.3.tar.gz -C /usr/<span class="built_in">local</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</span><br><span class="line">mv ./hadoop-2.7.3/ ./hadoop</span><br></pre></td></tr></table></figure>
<h3 id="2-配置环境变量"><a href="#2-配置环境变量" class="headerlink" title="2.配置环境变量"></a>2.配置环境变量</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>​        在打开对话框中添加下列路径：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#hadoop</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_INSTALL=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$HADOOP_HOME</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<h3 id="3-修改配置文件"><a href="#3-修改配置文件" class="headerlink" title="3.修改配置文件"></a>3.修改配置文件</h3><p>​        Hadoop运行方式由其相关配置文件决定，因此在运行前需要修改配置文件。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>
<ul>
<li><p>修改slaves、masters文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim slaves</span><br></pre></td></tr></table></figure>
<p>在弹出窗口中输入作为slaves节点的节点名称：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim masters</span><br></pre></td></tr></table></figure>
<p>在弹出窗口中输入作为master节点的节点名称：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改core-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">description</span>&gt;</span>Abase for other temporary directories.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改hdfs-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:50090<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/hadoop/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改mapred-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp mapred-site.xml.template mapred-site.xml  <span class="comment"># 复制模板</span></span><br><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改yarn-site.xml</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="三、安装Scala和Spark-2-1-1"><a href="#三、安装Scala和Spark-2-1-1" class="headerlink" title="三、安装Scala和Spark 2.1.1"></a>三、安装Scala和Spark 2.1.1</h2><h3 id="1-下载并安装-1"><a href="#1-下载并安装-1" class="headerlink" title="1.下载并安装"></a>1.下载并安装</h3><p>由于spark 2.0 采用scala 2.11.8版本编译，因此考虑下载scala 2.11.8</p>
<p><strong><a href="https://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz" target="_blank" rel="noopener">Scala 2.11.8 下载地址</a></strong></p>
<p><strong><a href="https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.1.1/spark-2.1.1-bin-hadoop2.7.tgz" target="_blank" rel="noopener">Spark 2.0 下载地址</a></strong></p>
<p>下载完毕后利用<code>WinSCP</code>将下载文件传输至download文件夹</p>
<h3 id="2-设置环境变量"><a href="#2-设置环境变量" class="headerlink" title="2.设置环境变量"></a>2.设置环境变量</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>​        在弹出对话框中输入下述路径：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/scala</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SCALA_HOME</span>/bin</span><br><span class="line"><span class="comment">#spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<h3 id="3-修改Spark相关配置"><a href="#3-修改Spark相关配置" class="headerlink" title="3.修改Spark相关配置"></a>3.修改Spark相关配置</h3><ul>
<li><p>修改slaves文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/conf</span><br><span class="line">cp slave.template slaves</span><br><span class="line">vim slaves</span><br></pre></td></tr></table></figure>
<p>​        在弹出对话框中输入作为slaves节点的节点名称（同时删除原有节点名称localhost）</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改spark-env.sh文件</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.template spark-env.sh</span><br><span class="line">vim spark-env.sh</span><br></pre></td></tr></table></figure>
<p>​        在弹出对话框中输入下述spark配置</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#java</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/java</span><br><span class="line"><span class="comment">#scala</span></span><br><span class="line"><span class="built_in">export</span> SCALA_HOME=/usr/<span class="built_in">local</span>/scala</span><br><span class="line"><span class="comment">#hadoop</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> YARN_CONF_DIR=/usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line"><span class="comment">#hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/hive</span><br><span class="line"><span class="built_in">export</span> HIVE_CONF_DIR=/usr/<span class="built_in">local</span>/hive/conf</span><br><span class="line"><span class="comment">#spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> SPARK_LOCAL_DIRS=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> SPARK_DIST_CLASSPATH=$(/usr/<span class="built_in">local</span>/hadoop/bin/hadoop classpath)</span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_CORES=1</span><br><span class="line"><span class="built_in">export</span> SPARK_WORKER_INSTANCES=2 </span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_IP=192.168.*.*       <span class="comment"># 填写master IP</span></span><br><span class="line"><span class="built_in">export</span> SPARK_MASTER_WEBUI_PORT=18080</span><br><span class="line"><span class="built_in">export</span> SPARK_LIBRARY_PATH=.:<span class="variable">$JAVA_HOME</span>/lib:<span class="variable">$JAVA_HOME</span>/jre/lib:<span class="variable">$HADOOP_HOME</span>/lib/native</span><br></pre></td></tr></table></figure>
<p>​        在配置文件中不仅包括各关键组件路径，还由包括主机IP在内的各运行参数。</p>
<p>​</p>
</li>
</ul>
<h2 id="四、部署其他节点"><a href="#四、部署其他节点" class="headerlink" title="四、部署其他节点"></a>四、部署其他节点</h2><h3 id="1-将虚拟机复制至其他节点"><a href="#1-将虚拟机复制至其他节点" class="headerlink" title="1.将虚拟机复制至其他节点"></a>1.将虚拟机复制至其他节点</h3><p>​        根据配置要求，复制虚拟机，本次部署在42上安装一个虚拟机作为master节点，在41及43服务器上分别安装3个虚拟机作为slaves节点。</p>
<h3 id="2-修改网络配置（举例，实际情况视本机IP而定）"><a href="#2-修改网络配置（举例，实际情况视本机IP而定）" class="headerlink" title="2.修改网络配置（举例，实际情况视本机IP而定）"></a>2.修改网络配置（举例，实际情况视本机IP而定）</h3><p>​        之前的网络设置只设置了开启网络，此时需要修改动态IP为静态IP，以master节点为例，进行下述操作：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/sysconfig/network-scripts</span><br><span class="line">ls</span><br><span class="line">vim ifcfg-ens160</span><br></pre></td></tr></table></figure>
<p>修改：</p>
<p>BOOTPROTO=static</p>
<p>IPADDR=192.168.2.220</p>
<p>NETMASK=255.255.240.0</p>
<p>GATEWAY=192.168.2.1</p>
<p>DNS1=192.168.2.1</p>
<p>DNS2=61.139.2.69</p>
<h3 id="3-修改各节点hostname"><a href="#3-修改各节点hostname" class="headerlink" title="3.修改各节点hostname"></a>3.修改各节点hostname</h3><p>​        根据运行功能，修改各节点hostname，master节点名称为master，其余节点统一设置名称为datax，以master节点为例。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hostname</span><br></pre></td></tr></table></figure>
<p>​        在弹出对话框中输入hostname（注意要删除原有（localhost）：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">master</span><br></pre></td></tr></table></figure>
<h3 id="4-修改各节点hosts映射关系"><a href="#4-修改各节点hosts映射关系" class="headerlink" title="4.修改各节点hosts映射关系"></a>4.修改各节点hosts映射关系</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure>
<p>​        在弹出对话框中输入hosts映射关系(注：原有部分不能删除)：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">192.168.2.220  master</span><br><span class="line">192.168.2.221  data</span><br></pre></td></tr></table></figure>
<h3 id="5-配置各节点免密码登陆"><a href="#5-配置各节点免密码登陆" class="headerlink" title="5.配置各节点免密码登陆"></a>5.配置各节点免密码登陆</h3><p>​        主要配置主节点（master）免密码登陆其他slaves节点，将主节点公钥授权至其他节点中。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/.ssh</span><br><span class="line">scp ~/.ssh/id_rsa.pub root@data1:~/download</span><br></pre></td></tr></table></figure>
<p>​        在data1上将公钥加入授权：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat ~/download/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><br><span class="line">rm -rf ~/download/id_rsa.pub    <span class="comment"># 用完即删</span></span><br></pre></td></tr></table></figure>
<p>​        测试是否能登陆data1</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh data1</span><br></pre></td></tr></table></figure>
<p>​        以此类推设置其他节点免密码登陆。</p>
<h3 id="6-测试Hadoop、Spark是否能够正常启动"><a href="#6-测试Hadoop、Spark是否能够正常启动" class="headerlink" title="6.测试Hadoop、Spark是否能够正常启动"></a>6.测试Hadoop、Spark是否能够正常启动</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format                   <span class="comment"># 对namenode进行格式化</span></span><br><span class="line">start-all.sh                            <span class="comment"># 启动hadoop相关进程</span></span><br><span class="line">/usr/<span class="built_in">local</span>/spark/sbin/start-all.sh      <span class="comment"># 启动spark相关进程</span></span><br></pre></td></tr></table></figure>
<p>  ​        在各监视端口查看各节点是否正常运行：</p>
<p>  ​        Hadoop监控端口：<a href="http://192.168.2.220:8088" target="_blank" rel="noopener">http://192.168.2.220:8088</a></p>
<p>​          HDFS监控端口：<a href="http://192.168.2.220:50070" target="_blank" rel="noopener">http://192.168.2.220:50070</a></p>
<p>​          Spark监控端口：<a href="http://192.168.2.220:18080" target="_blank" rel="noopener">http://192.168.2.220:18080</a></p>
<h2 id="五、安装Hive-1-2-2"><a href="#五、安装Hive-1-2-2" class="headerlink" title="五、安装Hive 1.2.2"></a>五、安装Hive 1.2.2</h2><h3 id="1-下载并安装-2"><a href="#1-下载并安装-2" class="headerlink" title="1.下载并安装"></a>1.下载并安装</h3><p>下载Hive 1.2.2 稳定版本：<strong><a href="https://mirrors.tuna.tsinghua.edu.cn/apache/hive/hive-1.2.2/apache-hive-1.2.2-bin.tar.gz" target="_blank" rel="noopener">下载地址</a></strong> </p>
<p> 利用<code>WinSCP</code>将下载文件复制到download文件夹。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf apache-hive-1.2.2-bin.tar.gz -C /usr/<span class="built_in">local</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">mv ./apache-hive-1.2.2-bin/ ./hive</span><br></pre></td></tr></table></figure>
<h3 id="2-添加环境变量"><a href="#2-添加环境变量" class="headerlink" title="2.添加环境变量"></a>2.添加环境变量</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>​        在弹出对话框中添加下述路径：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/hive</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HIVE_HOME</span>/bin</span><br></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>
<h3 id="3-修改相关配置"><a href="#3-修改相关配置" class="headerlink" title="3.修改相关配置"></a>3.修改相关配置</h3><p>​        由于使用Zeppelin作为Hive调度方法，仅涉及到使用Hive计算框架(MR)的使用，因此只需要使用默认配置即可。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/hive/conf</span><br><span class="line">cp hive-default.xml.template hive-default.xml</span><br></pre></td></tr></table></figure>
<h2 id="六、安装Zeppelin-0-7-0"><a href="#六、安装Zeppelin-0-7-0" class="headerlink" title="六、安装Zeppelin 0.7.0"></a>六、安装Zeppelin 0.7.0</h2><h3 id="1-下载并安装-3"><a href="#1-下载并安装-3" class="headerlink" title="1.下载并安装"></a>1.下载并安装</h3><p>下载Zeppelin 0.7.0版本：<strong><a href="http://archive.apache.org/dist/zeppelin/zeppelin-0.7.0/zeppelin-0.7.0-bin-all.tgz" target="_blank" rel="noopener">下载地址</a></strong></p>
<p>利用<code>WinSCP</code>传输下载文件至download文件夹。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf ~/download/zeppelin-0.7.0-bin-all.tgz -C /usr/<span class="built_in">local</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</span><br><span class="line">mv ./zeppelin-0.7.0-bin-all/ ./zeppelin</span><br></pre></td></tr></table></figure>
<h3 id="2-使用spark相关jar包替换zeppelin相关jar包"><a href="#2-使用spark相关jar包替换zeppelin相关jar包" class="headerlink" title="2.使用spark相关jar包替换zeppelin相关jar包"></a>2.使用spark相关jar包替换zeppelin相关jar包</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/zeppelin/lib</span><br><span class="line">rm -rf jackson-annotation&lt;Tab&gt;</span><br><span class="line">rm -rf jackson-core&lt;Tab&gt;</span><br><span class="line">rm -rf jackson-databind&lt;Tab&gt;</span><br><span class="line">rm -rf hadoop-annotation-2.6.0.jar</span><br><span class="line">rm -rf hadoop-auth-2.6.0.jar</span><br><span class="line">rm -rf hadoop-common-2.6.0.jar</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/spark/jars</span><br><span class="line">cp jackson-annotation-2.6.5.jar /usr/<span class="built_in">local</span>/zeppelin/lib</span><br><span class="line">cp jackson-core-2.6.5.jar /usr/<span class="built_in">local</span>/zeppelin/lib</span><br><span class="line">cp jackson-databind-2.6.5.jar /usr/<span class="built_in">local</span>/zeppelin/lib</span><br><span class="line">cp hadoop-annotation-2.7.3.jar /usr/<span class="built_in">local</span>/zeppelin/lib</span><br><span class="line">cp hadoop-auth-2.7.3.jar /usr/<span class="built_in">local</span>/zeppelin/lib</span><br><span class="line">cp hadoop-common-2.7.3.jar /usr/<span class="built_in">local</span>/zeppelin/lib</span><br></pre></td></tr></table></figure>
<h3 id="3-修改Zeppelin配置"><a href="#3-修改Zeppelin配置" class="headerlink" title="3.修改Zeppelin配置"></a>3.修改Zeppelin配置</h3><ul>
<li>修改site相关配置：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/zeppelin/conf</span><br><span class="line">cp zeppelin-site.xml.template zeppelin-site.xml</span><br><span class="line">vim zeppelin-site.xml</span><br></pre></td></tr></table></figure>
<p>(可选)设置无法匿名登陆以增加安全性：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>zeppelin.anonymous.allowed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Anonymous user allowed by default<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>设置登陆端口以避免冲突：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>zeppelin.server.port<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>28080<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>Server port.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>修改env相关配置</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp zeppelin-env.sh.template zeppelin-env.sh</span><br><span class="line">vim zeppelin-env.sh</span><br></pre></td></tr></table></figure>
<p>在弹出对话框中加入下述路径：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#java</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=/usr/<span class="built_in">local</span>/java</span><br><span class="line"><span class="comment">#hadoop</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIF=/usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br><span class="line"><span class="comment">#spark</span></span><br><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> MASTER=spark://192.168.*.*:7077               <span class="comment"># 填写master IP</span></span><br><span class="line"><span class="comment">#hive</span></span><br><span class="line"><span class="built_in">export</span> HIVE_HOME=/usr/<span class="built_in">local</span>/hive</span><br><span class="line"><span class="comment">#python</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=/usr/bin/python</span><br><span class="line"><span class="built_in">export</span> PYTHON_HOME=/usr/bin/python</span><br></pre></td></tr></table></figure>
<ul>
<li><p>测试能否正常启动Zeppelin(注：要先启动hadoop和spark相关服务)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-all.sh                                              <span class="comment"># 启动hadoop</span></span><br><span class="line">/usr/<span class="built_in">local</span>/spark/sbin/start-all.sh                        <span class="comment"># 启动Spark</span></span><br><span class="line">/usr/<span class="built_in">local</span>/zeppelin/bin/zeppelin-daemon.sh start          <span class="comment"># 启动Zeppelin</span></span><br></pre></td></tr></table></figure>
<ul>
<li>监控端口：</li>
</ul>
<p>Hadoop：<a href="http://masterIP:8088" target="_blank" rel="noopener">http://masterIP:8088</a></p>
<p>HDFS：<a href="http://masterIP:50070" target="_blank" rel="noopener">http://masterIP:50070</a></p>
<p>Spark：<a href="http://masterIP:18080" target="_blank" rel="noopener">http://masterIP:18080</a></p>
<p>Zeppelin：<a href="http://masterIP:28080" target="_blank" rel="noopener">http://masterIP:28080</a></p>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Environment/" rel="tag"><i class="fa fa-tag"></i> Environment</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/hexo-github.html" rel="next" title="hexo+github+mac+coding搭建hexo-next主题个人博客详解">
                <i class="fa fa-chevron-left"></i> hexo+github+mac+coding搭建hexo-next主题个人博客详解
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/JavaMysql.html" rel="prev" title="JavaMysql">
                JavaMysql <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNTIxOC8xMTc1NA=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘知行</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">48</span>
                  <span class="site-state-item-name">Artikel</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">Kategorien</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">16</span>
                  <span class="site-state-item-name">Tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hooog" target="_blank" title="Github">
                      
                        <i class="fa fa-fw fa-globe"></i>Github</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hooog" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-globe"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hooog" target="_blank" title="简书">
                      
                        <i class="fa fa-fw fa-globe"></i>简书</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、基础软件准备"><span class="nav-number">1.</span> <span class="nav-text">一、基础软件准备</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-虚拟机软件选择与安装"><span class="nav-number">1.1.</span> <span class="nav-text">1.虚拟机软件选择与安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-1-主流虚拟机软件介绍与选择"><span class="nav-number">1.1.1.</span> <span class="nav-text">1.1 主流虚拟机软件介绍与选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-Virtual-Box下载与安装"><span class="nav-number">1.1.2.</span> <span class="nav-text">1.2 Virtual Box下载与安装</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Linux操作系统选择与安装"><span class="nav-number">1.2.</span> <span class="nav-text">2.Linux操作系统选择与安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-Linux系统选择"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.1 Linux系统选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-Ubuntu操作系统选择与安装"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2 Ubuntu操作系统选择与安装</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-1系统选择"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">2.2.1系统选择</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-2系统安装"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">2.2.2系统安装</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-其他功能软件准备与安装"><span class="nav-number">1.3.</span> <span class="nav-text">3.其他功能软件准备与安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-模拟终端软件下载与安装"><span class="nav-number">1.3.1.</span> <span class="nav-text">3.1 模拟终端软件下载与安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-图形化SFTP（安全文件传输协议）客户端下载"><span class="nav-number">1.3.2.</span> <span class="nav-text">3.2 图形化SFTP（安全文件传输协议）客户端下载</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、Hadoop单机模式与伪分布式的安装与配置"><span class="nav-number">2.</span> <span class="nav-text">二、Hadoop单机模式与伪分布式的安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-Hadoop版本选择"><span class="nav-number">2.1.</span> <span class="nav-text">1.Hadoop版本选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Hadoop下载与安装"><span class="nav-number">2.2.</span> <span class="nav-text">2.Hadoop下载与安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-Apache-Hadoop下载"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.1 Apache Hadoop下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-Apache-Hadoop安装"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2 Apache Hadoop安装</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#2-2-1-Ubuntu中安装Hadoop"><span class="nav-number">2.2.2.1.</span> <span class="nav-text">2.2.1 Ubuntu中安装Hadoop</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-Hadoop单机模式配置与运行"><span class="nav-number">2.3.</span> <span class="nav-text">3.Hadoop单机模式配置与运行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Hadoop伪分布式配置与运行"><span class="nav-number">2.4.</span> <span class="nav-text">4.Hadoop伪分布式配置与运行</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-修改hadoop-env-sh"><span class="nav-number">2.4.1.</span> <span class="nav-text">4.1 修改hadoop-env.sh</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-修改core-site-xml文件"><span class="nav-number">2.4.2.</span> <span class="nav-text">4.2 修改core-site.xml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-修改hdfs-site-xml文件"><span class="nav-number">2.4.3.</span> <span class="nav-text">4.3 修改hdfs-site.xml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-修改mapred-site-xml文件"><span class="nav-number">2.4.4.</span> <span class="nav-text">4.4 修改mapred-site.xml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-修改yarn-site-xml文件"><span class="nav-number">2.4.5.</span> <span class="nav-text">4.5 修改yarn-site.xml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-6启动集群"><span class="nav-number">2.4.6.</span> <span class="nav-text">4.6启动集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-7-测试运行"><span class="nav-number">2.4.7.</span> <span class="nav-text">4.7 测试运行</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、Hadoop生态部分核心组件安装与配置"><span class="nav-number">3.</span> <span class="nav-text">三、Hadoop生态部分核心组件安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-ZooKeeper安装与配置"><span class="nav-number">3.1.</span> <span class="nav-text">1.ZooKeeper安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-ZooKeeper安装与配置"><span class="nav-number">3.1.1.</span> <span class="nav-text">1.2 ZooKeeper安装与配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-Spark安装与配置"><span class="nav-number">3.2.</span> <span class="nav-text">2.Spark安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-Scala下载与安装"><span class="nav-number">3.2.1.</span> <span class="nav-text">2.1 Scala下载与安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-Spark下载"><span class="nav-number">3.2.2.</span> <span class="nav-text">2.2 Spark下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-Spark安装与配置"><span class="nav-number">3.2.3.</span> <span class="nav-text">2.3 Spark安装与配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-HBase安装与配置"><span class="nav-number">3.3.</span> <span class="nav-text">3.HBase安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1HBase下载"><span class="nav-number">3.3.1.</span> <span class="nav-text">3.1HBase下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-安装与配置"><span class="nav-number">3.3.2.</span> <span class="nav-text">3.2 安装与配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-Hive安装与配置"><span class="nav-number">3.4.</span> <span class="nav-text">4.Hive安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1Hive下载"><span class="nav-number">3.4.1.</span> <span class="nav-text">4.1Hive下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-安装与配置"><span class="nav-number">3.4.2.</span> <span class="nav-text">4.2 安装与配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-Sqoop安装与配置"><span class="nav-number">3.5.</span> <span class="nav-text">5.Sqoop安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-1-Sqoop下载"><span class="nav-number">3.5.1.</span> <span class="nav-text">5.1 Sqoop下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-2-Sqoop安装与配置"><span class="nav-number">3.5.2.</span> <span class="nav-text">5.2 Sqoop安装与配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-Zeppelin安装与配置"><span class="nav-number">3.6.</span> <span class="nav-text">6.Zeppelin安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#6-1-Zeppelin下载"><span class="nav-number">3.6.1.</span> <span class="nav-text">6.1 Zeppelin下载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-2-Zeppelin安装与配置"><span class="nav-number">3.6.2.</span> <span class="nav-text">6.2 Zeppelin安装与配置</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、Hadoop分布式集群安装与配置"><span class="nav-number">4.</span> <span class="nav-text">四、Hadoop分布式集群安装与配置</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-复制虚拟机"><span class="nav-number">4.1.</span> <span class="nav-text">1.复制虚拟机</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-设置slave1虚拟机"><span class="nav-number">4.2.</span> <span class="nav-text">2.设置slave1虚拟机</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-配置虚拟机网络"><span class="nav-number">4.2.1.</span> <span class="nav-text">2.1 配置虚拟机网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-设置hostname"><span class="nav-number">4.2.2.</span> <span class="nav-text">2.2 设置hostname</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-设置hosts映射"><span class="nav-number">4.2.3.</span> <span class="nav-text">2.3 设置hosts映射</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-更改Hadoop相关配置"><span class="nav-number">4.2.4.</span> <span class="nav-text">2.4 更改Hadoop相关配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5-更改Spark相关配置"><span class="nav-number">4.2.5.</span> <span class="nav-text">2.5 更改Spark相关配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-6-更改ZooKeeper相关配置"><span class="nav-number">4.2.6.</span> <span class="nav-text">2.6 更改ZooKeeper相关配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-7-更改HBase相关配置"><span class="nav-number">4.2.7.</span> <span class="nav-text">2.7 更改HBase相关配置</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-复制slave1"><span class="nav-number">4.3.</span> <span class="nav-text">3.复制slave1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-启动集群"><span class="nav-number">4.4.</span> <span class="nav-text">5.启动集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-创建文件夹：mkdir"><span class="nav-number">4.5.</span> <span class="nav-text">3.创建文件夹：mkdir</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#附录二：HDFS基本操作指令"><span class="nav-number">5.</span> <span class="nav-text">附录二：HDFS基本操作指令</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-HDFS的shell命令方式"><span class="nav-number">5.1.</span> <span class="nav-text">1.HDFS的shell命令方式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-创建HDFS目录"><span class="nav-number">5.2.</span> <span class="nav-text">2.创建HDFS目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-查看HDFS目录"><span class="nav-number">5.3.</span> <span class="nav-text">3.查看HDFS目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-复制本地文件到HDFS"><span class="nav-number">5.4.</span> <span class="nav-text">4.复制本地文件到HDFS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-使用put命令复制本地文件到HDFS"><span class="nav-number">5.5.</span> <span class="nav-text">5.使用put命令复制本地文件到HDFS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-列出HDFS目录下文件内容"><span class="nav-number">5.6.</span> <span class="nav-text">6.列出HDFS目录下文件内容</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-使用copy命令复制HDFS至本地"><span class="nav-number">5.7.</span> <span class="nav-text">7.使用copy命令复制HDFS至本地</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-使用get命令复制HDFS文件至本地"><span class="nav-number">5.8.</span> <span class="nav-text">8.使用get命令复制HDFS文件至本地</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-复制HDFS文件"><span class="nav-number">5.9.</span> <span class="nav-text">9.复制HDFS文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-删除HDFS文件"><span class="nav-number">5.10.</span> <span class="nav-text">10.删除HDFS文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-下载源码"><span class="nav-number">5.11.</span> <span class="nav-text">1.下载源码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-将依赖jar包放入路径"><span class="nav-number">5.12.</span> <span class="nav-text">2.将依赖jar包放入路径</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-运行WordCount-java"><span class="nav-number">5.13.</span> <span class="nav-text">3.运行WordCount.java</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-创建表"><span class="nav-number">5.14.</span> <span class="nav-text">1.创建表</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-添加数据"><span class="nav-number">5.15.</span> <span class="nav-text">2.添加数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-查看、删除数据"><span class="nav-number">5.16.</span> <span class="nav-text">3.查看、删除数据</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#一、准备CentOS-7-2"><span class="nav-number">6.</span> <span class="nav-text">一、准备CentOS 7.2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-修改网络配置"><span class="nav-number">6.1.</span> <span class="nav-text">1.修改网络配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-安装部分需求组件"><span class="nav-number">6.2.</span> <span class="nav-text">2.安装部分需求组件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-验证本机无密码登陆"><span class="nav-number">6.3.</span> <span class="nav-text">3.验证本机无密码登陆</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-安装java-8"><span class="nav-number">6.4.</span> <span class="nav-text">4.安装java 8</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-关闭防火墙"><span class="nav-number">6.5.</span> <span class="nav-text">5.关闭防火墙</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-设置SELinux"><span class="nav-number">6.6.</span> <span class="nav-text">6.设置SELinux</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-配置ntp服务"><span class="nav-number">6.7.</span> <span class="nav-text">7.配置ntp服务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-配置httpd服务"><span class="nav-number">6.8.</span> <span class="nav-text">8.配置httpd服务</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、安装Hadoop-2-7-3"><span class="nav-number">7.</span> <span class="nav-text">二、安装Hadoop 2.7.3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-下载并安装"><span class="nav-number">7.1.</span> <span class="nav-text">1.下载并安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-配置环境变量"><span class="nav-number">7.2.</span> <span class="nav-text">2.配置环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-修改配置文件"><span class="nav-number">7.3.</span> <span class="nav-text">3.修改配置文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、安装Scala和Spark-2-1-1"><span class="nav-number">8.</span> <span class="nav-text">三、安装Scala和Spark 2.1.1</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-下载并安装-1"><span class="nav-number">8.1.</span> <span class="nav-text">1.下载并安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-设置环境变量"><span class="nav-number">8.2.</span> <span class="nav-text">2.设置环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-修改Spark相关配置"><span class="nav-number">8.3.</span> <span class="nav-text">3.修改Spark相关配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四、部署其他节点"><span class="nav-number">9.</span> <span class="nav-text">四、部署其他节点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-将虚拟机复制至其他节点"><span class="nav-number">9.1.</span> <span class="nav-text">1.将虚拟机复制至其他节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-修改网络配置（举例，实际情况视本机IP而定）"><span class="nav-number">9.2.</span> <span class="nav-text">2.修改网络配置（举例，实际情况视本机IP而定）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-修改各节点hostname"><span class="nav-number">9.3.</span> <span class="nav-text">3.修改各节点hostname</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-修改各节点hosts映射关系"><span class="nav-number">9.4.</span> <span class="nav-text">4.修改各节点hosts映射关系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-配置各节点免密码登陆"><span class="nav-number">9.5.</span> <span class="nav-text">5.配置各节点免密码登陆</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-测试Hadoop、Spark是否能够正常启动"><span class="nav-number">9.6.</span> <span class="nav-text">6.测试Hadoop、Spark是否能够正常启动</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#五、安装Hive-1-2-2"><span class="nav-number">10.</span> <span class="nav-text">五、安装Hive 1.2.2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-下载并安装-2"><span class="nav-number">10.1.</span> <span class="nav-text">1.下载并安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-添加环境变量"><span class="nav-number">10.2.</span> <span class="nav-text">2.添加环境变量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-修改相关配置"><span class="nav-number">10.3.</span> <span class="nav-text">3.修改相关配置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#六、安装Zeppelin-0-7-0"><span class="nav-number">11.</span> <span class="nav-text">六、安装Zeppelin 0.7.0</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-下载并安装-3"><span class="nav-number">11.1.</span> <span class="nav-text">1.下载并安装</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-使用spark相关jar包替换zeppelin相关jar包"><span class="nav-number">11.2.</span> <span class="nav-text">2.使用spark相关jar包替换zeppelin相关jar包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-修改Zeppelin配置"><span class="nav-number">11.3.</span> <span class="nav-text">3.修改Zeppelin配置</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘知行</span>

  
</div>


  <div class="powered-by">
  <span>Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></span>
  </div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 本站访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
