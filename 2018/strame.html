<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="spark," />





  <link rel="alternate" href="/atom.xml" title="Hoooge's Blog" type="application/atom+xml" />






<meta name="description" content="流式处理框架 Spark Streaming 很多企业为了支持决策分析而构建的数据仓库系统，其中存放的大量历史数据就是静态数据。 对于技术人员来说，可以利用数据挖掘和OLAP（On-Line Analytical Processing）分析工具从中找到对企业有价值的信息，这也是离线批处理的一般过程。  目录 流式处理框架基础 Flume Kafka  1. 流式处理框架基础1.1 流数据一般特征流">
<meta name="keywords" content="spark">
<meta property="og:type" content="article">
<meta property="og:title" content="流式处理框架 &amp; Spark Streaming &amp; Flume &amp; Kafka">
<meta property="og:url" content="http://www.ihoge.cn/2018/strame.html">
<meta property="og:site_name" content="Hoooge&#39;s Blog">
<meta property="og:description" content="流式处理框架 Spark Streaming 很多企业为了支持决策分析而构建的数据仓库系统，其中存放的大量历史数据就是静态数据。 对于技术人员来说，可以利用数据挖掘和OLAP（On-Line Analytical Processing）分析工具从中找到对企业有价值的信息，这也是离线批处理的一般过程。  目录 流式处理框架基础 Flume Kafka  1. 流式处理框架基础1.1 流数据一般特征流">
<meta property="og:image" content="http://p6rvh6ej2.bkt.clouddn.com/15241530856455.jpg">
<meta property="og:image" content="http://p6rvh6ej2.bkt.clouddn.com/15241530202093.jpg">
<meta property="og:image" content="http://p6rvh6ej2.bkt.clouddn.com/15241531282473.jpg">
<meta property="og:image" content="http://p6rvh6ej2.bkt.clouddn.com/15241532271911.jpg">
<meta property="og:image" content="http://p6rvh6ej2.bkt.clouddn.com/15241532641098.jpg">
<meta property="og:image" content="http://p6rvh6ej2.bkt.clouddn.com/15241533218101.jpg">
<meta property="og:updated_time" content="2018-04-22T14:55:14.911Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="流式处理框架 &amp; Spark Streaming &amp; Flume &amp; Kafka">
<meta name="twitter:description" content="流式处理框架 Spark Streaming 很多企业为了支持决策分析而构建的数据仓库系统，其中存放的大量历史数据就是静态数据。 对于技术人员来说，可以利用数据挖掘和OLAP（On-Line Analytical Processing）分析工具从中找到对企业有价值的信息，这也是离线批处理的一般过程。  目录 流式处理框架基础 Flume Kafka  1. 流式处理框架基础1.1 流数据一般特征流">
<meta name="twitter:image" content="http://p6rvh6ej2.bkt.clouddn.com/15241530856455.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.ihoge.cn/2018/strame.html"/>





  <title>流式处理框架 & Spark Streaming & Flume & Kafka | Hoooge's Blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/hooog" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hoooge's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Life is short</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://www.ihoge.cn/2018/strame.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="刘知行">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hoooge's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">流式处理框架 & Spark Streaming & Flume & Kafka</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-04-19T10:59:21+08:00">
                2018-04-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 浏览
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>K
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="流式处理框架-Spark-Streaming"><a href="#流式处理框架-Spark-Streaming" class="headerlink" title="流式处理框架 Spark Streaming"></a>流式处理框架 Spark Streaming</h1><ul>
<li>很多企业为了支持决策分析而构建的数据仓库系统，其中存放的大量历史数据就是静态数据。</li>
<li>对于技术人员来说，可以利用数据挖掘和OLAP（On-Line Analytical Processing）分析工具从中找到对企业有价值的信息，这也是离线批处理的一般过程。<br><img src="http://p6rvh6ej2.bkt.clouddn.com/15241530856455.jpg" alt=""></li>
</ul>
<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol>
<li>流式处理框架基础</li>
<li>Flume</li>
<li>Kafka</li>
</ol>
<h2 id="1-流式处理框架基础"><a href="#1-流式处理框架基础" class="headerlink" title="1. 流式处理框架基础"></a>1. 流式处理框架基础</h2><h3 id="1-1-流数据一般特征"><a href="#1-1-流数据一般特征" class="headerlink" title="1.1 流数据一般特征"></a>1.1 流数据一般特征</h3><p><strong>流数据具有如下特征：</strong></p>
<ul>
<li>数据快速持续到达，潜在大小也许是无穷无尽的；<ul>
<li>数据来源众多，格式复杂；</li>
<li>数据量大，但是不十分关注存储，一旦经过处理，要么被丢弃，要么被归档存储；</li>
<li>注重数据的整体价值，不过分关注个别数据；</li>
<li>数据顺序颠倒，或者不完整，系统无法控制将要处理的新到达的数据元素的顺序；</li>
</ul>
</li>
</ul>
<p>因此，用于静态数据存储的存储工具和批处理计算框架便无法满足流式计算、实时分析的应用需求。</p>
<h3 id="1-2-实时计算的核心框架"><a href="#1-2-实时计算的核心框架" class="headerlink" title="1.2 实时计算的核心框架"></a>1.2 实时计算的核心框架</h3><p><img src="http://p6rvh6ej2.bkt.clouddn.com/15241530202093.jpg" alt=""></p>
<h3 id="1-3-数据源"><a href="#1-3-数据源" class="headerlink" title="1.3 数据源"></a>1.3 数据源</h3><p><strong>为何数据源在流式计算中显得异常重要</strong></p>
<p>所谓数据源，是指为了满足不同需求而不断输出数据的框架。不同于针对静态数据的批处理，要进行实时计算，就必须有足够“实时”且能够稳定运行的消息“投递者”，它必须能够高效的整合更低一级数据源发送的实时数据，并根据处理框架的API对数据进行规范化处理和转存，同时，对于流式处理系统而言，很多时候经过流式处理框架处理后的数据也是流数据，也可视作一种数据源。</p>
<p><strong>数据源的高低级之分</strong></p>
<p>对于流式处理框架而言，数据源的高低级之分，其实就是数据“输出”框架的高低级之分。任何数据源，要进行收集、转存和传递等工作，就需要有与之对应的处理框架，其框架越完善、功能越强大、且能够提供更便于实时处理的数据，我们就称其高级数据源，反之就称为低级数据源。</p>
<p><strong>数据源本身的“处理框架”</strong></p>
<p>这其实并不是规范的说法，通常来说，低级数据源我们会直接称呼其数据流，如文件流、套接字流等，而高级数据源，我们更多的会根据其作用，称其为日志收集系统（如Flume），或分布式消息队列（如Kafka）。对于初学者而言，我们可以将这些复杂的框架名称统一想象成一个数据的中转站，这些框架的核心作用都是收集、暂存然后投递数据。</p>
<p><strong>大数据分析师的知识边界</strong></p>
<p>一方面，我们要进行流式计算，就必须了解数据源对计算框架投递消息的方法，如此才能根据数据源设计算法，或者根据计算需求调整数据源；另一方面，我们也要区别大数据分析师与ETL工程师的区别，我们只需要了解与计算框架最近一层的数据源是如何与计算框架相互嵌套的既可，而无需再深究该数据源更低一层数据源、甚至是数据产生第一层数据源是如何工作的。</p>
<h2 id="2-Flume"><a href="#2-Flume" class="headerlink" title="2. Flume"></a>2. Flume</h2><h3 id="2-1-Flume介绍"><a href="#2-1-Flume介绍" class="headerlink" title="2.1 Flume介绍"></a>2.1 Flume介绍</h3><p>Flume是Cloudera公司开发的分布式、高可用的日志收集系统。现已开源给Apache。<br>目前比较有代表性的日志收集系统，除了Flume之外，还有FaceBook的Scribe。</p>
<p>Flume原始版本为OG，后经过整体架构的重新设计，以改名为Flume-NG。Flume发展至今，已不限于日志收集，还可以通过简单的配置，收集不同数据源的海量数据并将数据准确高效的传输到不同的处理框架或数据存储系统。<br>目前Flume可对接的主流大数据框架有Hadoop、Kafka、Hive、HBase、Spark等。</p>
<h3 id="2-2-Flume基本架构"><a href="#2-2-Flume基本架构" class="headerlink" title="2.2 Flume基本架构"></a>2.2 Flume基本架构</h3><p>Flume-NG采用三层架构设计，分别对应其三个核心组件：Source、Channel和Sink，其中，Source主要功能为收集上一层数据源传输过来的数据，Channel用于数据的暂时存储，Sink则用于数据的处理，即数据的传输对象和传输方式。其基本架构如下图所示：<br><img src="http://p6rvh6ej2.bkt.clouddn.com/15241531282473.jpg" alt=""></p>
<p>其中，一个Agent代表一个Java进程，上图表示一个Event（数据）在一个Agent的传输流程。</p>
<ul>
<li><code>Event</code>：一条消息或者一个数据，具有可选的头信息，在头信息中可以设置时间戳、主机名等信息；</li>
<li><code>Source</code>：数据源，接收或者收集不同形式的数据源；</li>
<li><code>Channel</code>：Event的临时缓冲区，Source接收的Event会先发送到Channel进行缓存，在缓冲区内等待Sink的消费；</li>
<li><code>Sink</code>：用于处理Channel中缓存的数据，并发送至下一层（处理框架、存储中心或者下一个Agent）；</li>
<li><code>Agent</code>：包含了Source、Channel、Sink等组件的Flume进程；</li>
<li><code>Interceptor</code>：Event拦截器，在数据进入Channel之前根据配置要求，对数据进行头信息（Header）编辑，添加时间戳、主机名称等；</li>
<li><code>Selector</code>：Event的选择器，即决定Event流入Channel的方式，主要有<code>复制</code>（Replicating）和<code>复用</code>（Multiplexing）两种选方式；</li>
<li><code>Sink Processor</code>：Event Sink处理器，Flume提供了故障转移处理器和负载均衡处理器两种。</li>
</ul>
<h3 id="2-3-Flume核心组件-Source"><a href="#2-3-Flume核心组件-Source" class="headerlink" title="2.3 Flume核心组件:Source"></a>2.3 Flume核心组件:Source</h3><p><strong>Source核心功能</strong></p>
<ul>
<li>用于对接各种数据源，并将收集到的Event发送至用于临时存储的Channel中。Flume中每个Agent对应一个Source，而每个Agent的Source在启动前必须通过修改配置变量来设置其接受消息种类，此即称为Source种类</li>
</ul>
<p><strong>常用Scoure种类</strong>(依据数据类型分类)</p>
<ul>
<li><p><code>Avro Source</code>：Avro是Doug Cutting牵头开发的一个数据序列化系统，设计用于支持大批量数据交换的应用。Avro Source支持Avro协议，接收RPC请求，<code>Avro Source</code>通过监听Avro端口接收外部Avro客户端流事件，在Flume的多层架构中经常被使用接收上游Sink发送的event。</p>
</li>
<li><p><code>Kafka Source</code>：对接分布式消息队列Kafka，作为Kafka的消费者持续从Kafka中拉取数据，如果多个kafka source同时消费Kafka中同一个Topic，则其会被设置为同组id，从而保证多个Kafka Source之间不会重复拉取数据。</p>
</li>
<li><p><code>Exec Source</code>：支持Linux命令，收集标准输出数据或者通过tail -f file的方式监听指定文件。Exce Source可以实现实时的消息传输，但却不会记录已读取的文件的位置，不支持断点续传，如果Exce Source重启或者挂掉都会造成后续增加的消息无法接收，建议只在测试环境中使用。</p>
</li>
<li><p><code>Spooling Directory Source</code>：用于监听一个文件夹，收集文件夹中新文件数据，手机玩新文件数据会将文件名称的后缀改为.completed，缺点是不支持老文件（已经completed的文件）中新增数据集的收集，并且不能够对嵌套文件夹进行递归监听。</p>
</li>
<li><p><code>Taildir Source</code>：监听一个文件或文件夹，通过正则表达式匹配需要监听的数据源文件，支持文件夹嵌套递归监听，Taildir Source通过将监听文件的位置写入到文件中，从而实现断点续传，并且能够保证没有重复的数据读取。</p>
</li>
</ul>
<h3 id="2-4-Flume核心组件-Channel"><a href="#2-4-Flume核心组件-Channel" class="headerlink" title="2.4 Flume核心组件:Channel"></a>2.4 Flume核心组件:Channel</h3><p><strong>Channel核心功能</strong></p>
<ul>
<li>Channel是Event的<code>临时缓冲区</code>，存储Source收集但尚未被Sink读取的Event，其目标是为平衡Source收集速度和Sink读取速度，可视为Flume内部的消息队列。Channel线程的安全性较高且具有事务性，支持Source写失败重复写和Sink读失败重复读等操作。同时，我们根据Channel存储方式划分Channel种类。</li>
</ul>
<p><strong>常用Channel种类</strong> (依据存储方式分类)</p>
<ul>
<li><p>Memory Channel：<code>缓冲区所有数据都存于内存</code>，Memory Channel读写速度快，但存储量受内存限制，且当Flume进程挂掉、服务器宕机或重启时都会造成数据丢失。建议在服务器内存充足，且不关心数据丢失的场景下使用。</p>
</li>
<li><p>File Channel：缓冲区所有数据写入磁盘，File Channel存储容量大，无数据丢失风险。File Channel数据存储路径可以配置多个磁盘文件路径，通过磁盘并行写入提高其性能，在写入磁盘时是顺序写入，且单个数据文件大小可通过配置文件中maxFileSize参数进行调整，当被写入文件大小超过上限时，Flume会自动创建新文件用来存储后续Event。但数据文件数量不会无限增长，一旦旧文件被Sink读取完成，就将被删除。Flume通过设置检查点和备份检查点实现Agent重启之后快速将File Channel中的数据按顺序回放到内存中，以保证Agent在失败重启后仍能快速安全地提供服务。</p>
</li>
<li><p><code>Kafka Channel</code>：值得一提的是，Kafka可作为Flume中Channel存储方式，Kafka是分布式、可扩展、高容错、高吞吐的分布式系统，Kafka通过其优秀的架构设计充分利用磁盘顺序读写特性，在廉价的硬件条件下就能完成高效的消息发布和订阅，对比其他两种Channel，Kafka Channel在读取速度、存储量和容错性上完美的弥补了二者短板，若能合理利用Kafka性能，能够达到事半功倍的效果。</p>
</li>
</ul>
<h3 id="2-5-Flume核心组件-Sink"><a href="#2-5-Flume核心组件-Sink" class="headerlink" title="2.5 Flume核心组件:Sink"></a>2.5 Flume核心组件:Sink</h3><p><strong>Sink核心功能</strong></p>
<ul>
<li>用于处理Channel中缓存的数据，当数据经过Sink Processor处理后由Sink进行后续处理，Sink可将数据传输至静态数据存储中心进行数据保存，也可以将数据传输至实时处理框架进行数据处理，当然，也可以将数据传输至下一层数据源，进行进一步数据聚合、整理或推送。</li>
</ul>
<p><strong>常用Sink种类</strong> (依据投递接收方划分)</p>
<ul>
<li><p>Avro Sink：Avro Sink常用于对接下一层Arvo Source，通过发送RPC请求将Event发送到下一层的Avro Source，同时，Avro Sink提供了端到端的批量压缩数据传输，从而解决RPC传输过程中占用大量网络资源以及产生大量Socket连接等问题。</p>
</li>
<li><p>HDFS Sink：HDFS作为Hadoop生态中的最常用文件系统，具有高容错、可扩展、高性能、低成本等特点，HDFS Sink通过将Event写入HDFS进行数据存储，能够有效、长期存储大量数据。</p>
</li>
<li><p>Kafka Sink：在消息传递过程中采用Kafka框架能够从很大程度上降低系统耦合度，从而增加系统系统稳定性和容错机制，Flume可通过Kafka Sink将Event写入Kafka的Topic，其他应用通过Kafka获得数据。Flume从1.7.0开始支持Kafka 0.9及以上版本。</p>
</li>
</ul>
<h3 id="Interceptor（拦截器）-与选择器配合使用"><a href="#Interceptor（拦截器）-与选择器配合使用" class="headerlink" title="Interceptor（拦截器） (与选择器配合使用)"></a>Interceptor（拦截器） (与选择器配合使用)</h3><p><strong>Interceptor（拦截器）功能介绍</strong></p>
<ul>
<li>Source将Event写入Channel之前，可以用拦截器对Event进行添加头信息等简单处理，Source和Channel之间可设多个拦截器，不同拦截器可根据自身规则对Event进行简单处理，注意，拦截器属于轻量级插件，无法应对复杂数据处理工作。</li>
</ul>
<p><strong>常用Interceptor</strong></p>
<ul>
<li><p>主机拦截器（Host Interceptor）：Flume通过主机拦截器在Event头信息中添加主机名称或者IP。通过主机拦截器，Channel可以根据不同的主机信息分区存储Event，后续Sink也可根据不同主机信息对Event进行分别处理。</p>
</li>
<li><p>静态拦截器（Static Interceptor）：主要用于修改、过滤Event在此被拦截之前所设置的信息。</p>
</li>
</ul>
<h3 id="Selector（选择器）-与拦截器配合使用"><a href="#Selector（选择器）-与拦截器配合使用" class="headerlink" title="Selector（选择器） (与拦截器配合使用)"></a>Selector（选择器） (与拦截器配合使用)</h3><p><strong>功能介绍</strong></p>
<ul>
<li>Source发送的Event通过Channel选择器来决定以何种方式写入Channel，Flume提供了三种常用的选择器，分别是复制Channel选择器（Replicating Channel Selector）、复用Channel选择器（Multiplexing Channel Selector）和自定义选择器。</li>
</ul>
<p><strong>常用选择器</strong></p>
<ul>
<li><p>复制选择器（ Replicating Channel Selector ）：是Flume选择器的默认模式，即不对选择器进行设置时采用的模式，此时Source将以复制的方式将一个Event写入多个Channel中，不同的Sink可从不同的的Channel中获得相同的数据。复制选择器用途较多，当一个Event要做多个用途时，可考虑用复制选择器。</p>
</li>
<li><p>复用Channel选择器（Multiplexing Channel Selector）：复用选择器需要配合拦截器共同使用，复用选择器会根据Event的头信息来判断每个Event应该写入哪个Channel中。<br><img src="http://p6rvh6ej2.bkt.clouddn.com/15241532271911.jpg" alt=""></p>
</li>
</ul>
<p>💡</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">关于负载均衡和故障排除的相关说明:</span><br><span class="line">Flume为了提高整体容错能力和稳定性，提供了负载均衡故障转移功能</span><br><span class="line">这两项功能配置较为简单，只要合理配置Sink组，并且在每组Sink中设置多个</span><br><span class="line">子Sink，就能够自动进行负载均衡和故障转移。</span><br></pre></td></tr></table></figure>
<h2 id="Kafka"><a href="#Kafka" class="headerlink" title="Kafka"></a>Kafka</h2><p>Kafka是由LinkedIn公司开源的分布式消息队列。现已加入到Apache软件基金会，并且凭借其高吞吐、可扩展、高可用、部署简单、开发接口丰富等特性，已在各大互联网公司的实际生产环境中广泛使用。<br>同时，大多数分布式处理系统都支持使用kafka，如Spark、Storm、Druid、Flume等<br><img src="http://p6rvh6ej2.bkt.clouddn.com/15241532641098.jpg" alt=""></p>
<h3 id="Kafka基本特点"><a href="#Kafka基本特点" class="headerlink" title="Kafka基本特点"></a>Kafka基本特点</h3><ul>
<li>Kafka其实就是消息“中转站”</li>
<li>Kafka本身不产生消息，也不对消息进行永久存储，它只是消息的“中转站”。</li>
</ul>
<ul>
<li>数据“中转站”至关重要</li>
<li>在实际工作中，我们广泛需要消息“中转站”的原因，是数据采集端种类各异，消息格式数据格式种类繁多，同时数据应用情景也非常复杂，提取数据可能为了实时计算，可能为了存储一段时间后进行批处理，也可能直接推送至数据产品前段，也可能中间夹杂各种其他过程以及各过程之间的复用。因此，我们需要“中转站”对数据进行暂存、简单处理、再次投递。</li>
</ul>
<ul>
<li>Kafka作为最优秀的消息“中转站”之一，并被广泛认可，完全得益于其优秀的架构。</li>
</ul>
<h3 id="Kafka构架特点"><a href="#Kafka构架特点" class="headerlink" title="Kafka构架特点"></a>Kafka构架特点</h3><ol>
<li>生产者和消费者不需要彼此了解</li>
<li>消费者的性能问题不会影响生产者</li>
<li>消费者受到保护，免受生产者的伤害</li>
<li>在处理负载方面有很大的灵活性</li>
<li>消息可供任何人使用 - </li>
<li>大量的新用例，监控，审计和故障排除</li>
</ol>
<ul>
<li>高吞吐率</li>
</ul>
<ol>
<li>Kafka利用顺序读写磁盘的设计，提供了可以和内存随机读写相匹敌的读写速度；</li>
<li>其灵活的客户端API设计，利用Linux操作系统提供的“零拷贝”特性，减少了消息网络传输的时间；</li>
<li>同时提供端到端的消息压缩传输，对同一主题下的消息采用分布式存储；</li>
</ol>
<ul>
<li>高容错、高可用</li>
</ul>
<p>Kafka在集群模式下允许用户对每个分区（partition）配置多个副本，且将副本均匀的分到各个节点（broker）内存储，保证同一个分区的副本不会再同一台机器上存储。同时，多副本之间采用Leader-Follower机制同步消息，只有Leader对外提供读写服务，当Leader意外失败、Broker进程关闭、服务器宕机等情况导致数据不可用时，kafka会从Follower中选择一个成为Leader继续提供读写服务。</p>
<ul>
<li>可拓展</li>
</ul>
<p>理论上Kafka的性能随着Broker的增加而增加，增加一个Broker只需为新增Broker设置一个唯一编号，配置文件编写完成后，Kafka就能通过ZooKeeper发现新的Broker，并投入使用。</p>
<ul>
<li>接藕</li>
</ul>
<p>Kafka内部能够将消息生产阶段和处理阶段分开，两个阶段互相独立，且各自能实现自己的处理逻辑，通过Kafka提供的消息写入和消费接口实现对消息的连接处理。两个阶段相互独立，不仅降低了自身复杂度，同时也实现了对外部框架提供部分服务的功能（如Flume中嵌入Kafka）。</p>
<ul>
<li><strong>峰值处理</strong></li>
</ul>
<p>实际工作中，经常会遇见数据在某个时间点爆发式增长（如双11），此时如果后台处理系统无法及时处理峰值需求，就会导致数据积压，严重时会导致系统崩溃。而若能合理使用Kafka进行数据中转，就相当于给系统接入了一个巨大的缓冲区，其既能接收持续暴增的请求，也能根据后台需求提供服务，进而提高了系统数据处理能力。</p>
<h3 id="Kafka基本架构"><a href="#Kafka基本架构" class="headerlink" title="Kafka基本架构"></a>Kafka基本架构</h3><p><img src="http://p6rvh6ej2.bkt.clouddn.com/15241533218101.jpg" alt=""></p>
<ul>
<li>Producer代表消息生产者</li>
<li>Consumer代表消息消费者</li>
<li>Broker代表Kafka集群中各节点</li>
<li>Partition表示消息的一个分区</li>
<li>ZooKeeper为Kafka集群提供资源调度服务</li>
</ul>
<h3 id="Kafka基本概念"><a href="#Kafka基本概念" class="headerlink" title="Kafka基本概念"></a>Kafka基本概念</h3><ul>
<li><p><strong>Broker</strong>：一个Kafka的实例就是一个Broker，相当于Flume中的Agent；</p>
</li>
<li><p><strong>Topic</strong>：主题，Kafka中同一类型数据集的名称，相当于数据库中的表，Producer将同一类型数据写入同一个Topic中，同一个Consumer或Consumer Group从同一个Topic中消费数据，同时，一个Topic在物理上会被分成多分存储到不同的物理机上；</p>
</li>
<li><p><strong>Partition</strong>：分区，一个Topic可设置多个分区，相当于把一个数据集分成多分，存储到不同分区中进行存储（类似于HDFS），分区命名规则为topicname-index；</p>
</li>
<li><p><strong>Segment</strong>：段文件，Kafka中最小存储单位，一个topic包含多个Partition，一个Partition又包含多个Segment，Segment以其内部消息的起始偏移量进行索引；</p>
</li>
<li><p><strong>Offset</strong>：消息的起始偏移量，可作为Segment的索引；</p>
</li>
<li><p>Replication：副本，一个Partition可有一个或多个副本，创建Topic时可设置副本数量；</p>
</li>
<li><p>Producer：消息生产者，负责向Kafka集群中发布消息；</p>
</li>
<li><p>Consumer Group：消费者组，一个Consumer Group可包含一个或多个Consumer，当一个topic被一个消费者组消费的时候，一条消息只能由其中一位消费者消费，不会出现多位消费者消费同一条信息的情况；</p>
</li>
<li><p>Consumer：消息消费者，可从指定topic中拉取消息；</p>
</li>
<li><p>ZooKeeper：kafka需要ZooKeeper对其进行协调管理，安装Kafka过程将自带一个ZooKeeper。</p>
</li>
</ul>
<h2 id="实操流程"><a href="#实操流程" class="headerlink" title="实操流程"></a>实操流程</h2><h3 id="单节点演示"><a href="#单节点演示" class="headerlink" title="单节点演示"></a>单节点演示</h3><ol>
<li><p>启动zoopeeper服务<br> <code>bin/zookeeper-server-start.sh config/zookeeper.properties</code></p>
</li>
<li><p>启动Kafka服务<br> <code>bin/kafka-server-start.sh config/server.properties</code></p>
</li>
<li><p>创建topic取名cdatest<br> <code>bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic cdatest</code></p>
</li>
<li><p>查看topic<br> <code>bin/kafka-topics.sh --list --zookeeper localhost:2181</code></p>
</li>
<li><p>启动生产者指定topic，并在终端输入测试数据<br> <code>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic cdatest</code></p>
</li>
<li><p>启动消费者指定topic<br> <code>bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic cdatest --from-beginning</code></p>
</li>
</ol>
<h3 id="集群模式测试"><a href="#集群模式测试" class="headerlink" title="集群模式测试"></a>集群模式测试</h3><ol>
<li><p>修改参数server.properties</p>
</li>
<li><p>启动zookeeper集群服务</p>
</li>
<li><p>启动kafka集群（分别在各节点执行）<br><code>./bin/kafka-server-start.sh config/server.properties</code></p>
</li>
<li><p>任意一个节点创建topic<br><code>./bin/kafka-topics.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 2 --partitions 3 --topic kktest</code></p>
</li>
<li><p>查看topic状态<br><code>./bin/kafka-topics.sh --describe --zookeeper master:2181,slave1:2181,slave2:2181 --topic kktest</code></p>
</li>
<li><p>创建producer，手动输入测试数据（以master为例）<br><code>./bin/kafka-console-producer.sh --broker-list master:9092 --topic kktest</code></p>
</li>
<li><p>以slave1为例创建consumer消费数据<br><code>./bin/kafka-console-consumer.sh --bootstrap-server slave1:9092 --from-beginning --topic kktest</code></p>
</li>
</ol>
<p><strong>可以在不同节点创建多个生产者和消费者</strong></p>
<h2 id="使用外部数据源进行数据传输"><a href="#使用外部数据源进行数据传输" class="headerlink" title="使用外部数据源进行数据传输"></a>使用外部数据源进行数据传输</h2><ol>
<li><p>启动Kafka，启动prodecer和consumer</p>
</li>
<li><p>在Kafka安装路径内创建test.txt然后执行:q</p>
</li>
<li>~/kafka/bin/connect-standalone.sh ~/kafka/config/connect-standalone.properties ~/kafka/config/connect-file-source.properties ~/kafka/config/connect-file-sink.properties</li>
</ol>
<p><strong>自定义模式读取外部文件时，有两个主要的配置文件</strong><br>connect-file-source.properties<br>connect-file-sink.properties</p>
<p>根据需要修改文件读取模式、文件路径、Topic等</p>
<h2 id="Kafka于Flume联合部署"><a href="#Kafka于Flume联合部署" class="headerlink" title="Kafka于Flume联合部署"></a>Kafka于Flume联合部署</h2><p>创建flume配置文件：如kafkaSource.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># Name the components on this agent    a1.sources = r1    a1.sinks = k1    a1.channels = c1   # Describe/configure the source    a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource    a1.sources.r1.kafka.topics = kafkaTopic  a1.sources.r1.kafka.bootstrap.servers = master:9092,slave1:9092,slave2:9092  # Describe the sink    a1.sinks.k1.type = logger # Use a channel which buffers events in memory    a1.channels.c1.type = memory    a1.channels.c1.capacity = 1000    a1.channels.c1.transactionCapacity = 100   # Bind the source and sink to the channel    a1.sources.r1.channels = c1    a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure>
<p>启动Flume：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~/flume/bin/flume-ng agent --conf ~/flume/conf --conf-file ~/flume/conf/kafkaSource.conf --name a1 -Dflume.root.logger=INFO,console</span><br></pre></td></tr></table></figure>
<p>创建kafkaTopic</p>
<p><code>~/kafka/bin/kafka-topics.sh --create --zookeeper master:2181,slave1:2181,slave2:2181 --replication-factor 2 --partitions 3 --topic kafkaTopic</code></p>
<p>创建producer，输入测试信息<br><code>~/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic sparkMLLib</code></p>
<p><strong>顺序出错的分析</strong></p>
<ol>
<li>Kafka传出来的数据顺序就已经被打乱</li>
<li>计算资源（虽然传输的数据很微小，但是集群的启动成本高昂）</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/spark/" rel="tag"><i class="fa fa-tag"></i> spark</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/IntroductionToSpark.html" rel="next" title="Spark的基本架构">
                <i class="fa fa-chevron-left"></i> Spark的基本架构
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/StructuredStreaming.html" rel="prev" title="Strutured Streaming(Spark 2.3)">
                Strutured Streaming(Spark 2.3) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNTIxOC8xMTc1NA=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">刘知行</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">49</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hooog" target="_blank" title="Github">
                      
                        <i class="fa fa-fw fa-globe"></i>Github</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hooog" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-globe"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hooog" target="_blank" title="简书">
                      
                        <i class="fa fa-fw fa-globe"></i>简书</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#流式处理框架-Spark-Streaming"><span class="nav-number">1.</span> <span class="nav-text">流式处理框架 Spark Streaming</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目录"><span class="nav-number">1.1.</span> <span class="nav-text">目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-流式处理框架基础"><span class="nav-number">1.2.</span> <span class="nav-text">1. 流式处理框架基础</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-流数据一般特征"><span class="nav-number">1.2.1.</span> <span class="nav-text">1.1 流数据一般特征</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-实时计算的核心框架"><span class="nav-number">1.2.2.</span> <span class="nav-text">1.2 实时计算的核心框架</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-数据源"><span class="nav-number">1.2.3.</span> <span class="nav-text">1.3 数据源</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Flume"><span class="nav-number">1.3.</span> <span class="nav-text">2. Flume</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Flume介绍"><span class="nav-number">1.3.1.</span> <span class="nav-text">2.1 Flume介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-Flume基本架构"><span class="nav-number">1.3.2.</span> <span class="nav-text">2.2 Flume基本架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Flume核心组件-Source"><span class="nav-number">1.3.3.</span> <span class="nav-text">2.3 Flume核心组件:Source</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-Flume核心组件-Channel"><span class="nav-number">1.3.4.</span> <span class="nav-text">2.4 Flume核心组件:Channel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-Flume核心组件-Sink"><span class="nav-number">1.3.5.</span> <span class="nav-text">2.5 Flume核心组件:Sink</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Interceptor（拦截器）-与选择器配合使用"><span class="nav-number">1.3.6.</span> <span class="nav-text">Interceptor（拦截器） (与选择器配合使用)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Selector（选择器）-与拦截器配合使用"><span class="nav-number">1.3.7.</span> <span class="nav-text">Selector（选择器） (与拦截器配合使用)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka"><span class="nav-number">1.4.</span> <span class="nav-text">Kafka</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka基本特点"><span class="nav-number">1.4.1.</span> <span class="nav-text">Kafka基本特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka构架特点"><span class="nav-number">1.4.2.</span> <span class="nav-text">Kafka构架特点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka基本架构"><span class="nav-number">1.4.3.</span> <span class="nav-text">Kafka基本架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kafka基本概念"><span class="nav-number">1.4.4.</span> <span class="nav-text">Kafka基本概念</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实操流程"><span class="nav-number">1.5.</span> <span class="nav-text">实操流程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#单节点演示"><span class="nav-number">1.5.1.</span> <span class="nav-text">单节点演示</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#集群模式测试"><span class="nav-number">1.5.2.</span> <span class="nav-text">集群模式测试</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用外部数据源进行数据传输"><span class="nav-number">1.6.</span> <span class="nav-text">使用外部数据源进行数据传输</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Kafka于Flume联合部署"><span class="nav-number">1.7.</span> <span class="nav-text">Kafka于Flume联合部署</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">刘知行</span>

  
</div>


  <div class="powered-by">
  <span>Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></span>
  </div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 本站访客数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
